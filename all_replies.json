[
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: Wont work without it",
    "Date and Time: 2023-09-01T09:22:59Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @joerefsland",
    "Reply: I couldn&#39;t find the sitekey under elements, but I found it under the network tab, then the response tab.",
    "Date and Time: 2023-10-03T18:48:42Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: The one that you get from 2captcha",
    "Date and Time: 2023-02-27T17:41:36Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @sujitbiswas1995",
    "Reply: @@codeRECODE I need my own API key from google twocaptcha?",
    "Date and Time: 2023-05-19T09:31:17Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: Not that I am aware of. Even if you could, it will be very slow. Wait for another cheaper solution that i will be posting soon.",
    "Date and Time: 2022-11-23T10:41:35Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @ajayjoseph8722",
    "Reply: \u200b@@codeRECODE is it not what 2captcha is doing right now for a price? We sent the site key and URL. They somehow receive the same captcha &quot;we&quot; are meant to solve. They solve the captcha and send tokens back to the site saying &quot;we&quot; have verified the captcha successfully. It will be interesting to know how exactly Google allows this. Can&#39;t wait for the upcoming post. Thanks",
    "Date and Time: 2022-11-24T09:42:49Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: Should not be an issue.",
    "Date and Time: 2022-11-17T10:02:01Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: Welcome!",
    "Date and Time: 2022-11-08T08:08:54Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: Interesting idea!",
    "Date and Time: 2022-09-26T18:04:21Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: See the video on cookies on this channel, should be helpful",
    "Date and Time: 2022-08-29T11:13:17Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @kushagranalwaya",
    "Reply: I&#39;m also looking for the same, did you find any solution yet?",
    "Date and Time: 2022-08-14T05:12:23Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: See the code - <a href=\"https://github.com/eupendra/2captcha_demo/blob/main/demo_requests.py\">https://github.com/eupendra/2captcha_demo/blob/main/demo_requests.py</a>",
    "Date and Time: 2022-07-12T12:11:23Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2022-04-21T04:45:16Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: Yes, <a href=\"https://courses.coderecode.com/\">https://courses.coderecode.com/</a>",
    "Date and Time: 2022-03-26T13:00:10Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @kattamanju3395",
    "Reply: @@codeRECODE ok sir",
    "Date and Time: 2022-03-26T13:01:37Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: You&#39;re welcome!",
    "Date and Time: 2022-03-23T11:13:48Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: Adding to my list.",
    "Date and Time: 2022-03-03T11:47:54Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: No.",
    "Date and Time: 2022-03-03T12:06:50Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it!",
    "Date and Time: 2022-02-09T12:27:23Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: That is a good idea. I will add to my list.<br>Meanwhile, see this <a href=\"https://docs.scrapy.org/en/latest/topics/item-pipeline.html#duplicates-filter\">https://docs.scrapy.org/en/latest/topics/item-pipeline.html#duplicates-filter</a>",
    "Date and Time: 2022-02-05T12:08:14Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: Happy to help",
    "Date and Time: 2022-02-05T11:19:21Z",
    " ",
    "Video Id: R6QddZzCOwM",
    "Replier Name: @codeRECODE",
    "Reply: You can handle that with conditional code. It will really depend on the site and the specific scenario.<br>Be warned that I DO NOT recommend breaking captcha as it implies violating the terms of sites.",
    "Date and Time: 2022-02-05T11:25:48Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Thank you. <br>The site structure has changed. The same code will not work.",
    "Date and Time: 2022-09-29T13:36:27Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2022-08-13T05:16:43Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Hi, I am not sure I got your question. If you mean do I work online, then yes. I do a lot of things and being a freelancer is one of them. :-)",
    "Date and Time: 2022-03-03T11:58:32Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @kattamanju3395",
    "Reply: @@codeRECODE tnq for ur reply sir and my question do I work online bcz I&#39;m searching for online work sir",
    "Date and Time: 2022-03-03T14:10:20Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @kingofyoutube9318",
    "Reply: How much data did it consume. I mean how many MBs or GBs did it take to scrape all those data?",
    "Date and Time: 2022-05-16T15:48:53Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @soumyadip112",
    "Reply: @@kingofyoutube9318 I forgot how much it took .<br>But not much  around 100 MB",
    "Date and Time: 2022-05-16T15:58:06Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @kingofyoutube9318",
    "Reply: @@soumyadip112 Wow, that&#39;s too low. Here I am worrying that it will take GBs worth of data. I procrastinated for 7 months. Now I&#39;m gonna do it.",
    "Date and Time: 2022-05-16T17:41:35Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Thanks. Will do a live soon \ud83d\ude03",
    "Date and Time: 2021-10-04T08:35:43Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @jsverma143",
    "Reply: Also I have been facing issue if I get javascript calling in the pagination ..unable to land on next page as the url keeps static",
    "Date and Time: 2021-10-04T08:45:05Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @jsverma143",
    "Reply: I have seen almost all your videos. You have cleared my doubt&#39;s .. but some of doubts are still alive.. I would like to ask if you allow me",
    "Date and Time: 2021-10-04T08:47:45Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Never measured. It will depend on how many pages/images/ or rather Bytes you are transferring. There can not be one single answer.",
    "Date and Time: 2021-09-14T04:12:56Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @kingofyoutube9318",
    "Reply: @@codeRECODE My data plan is 2gb per day. Is it enough? If it&#39;s not enough, then I&#39;m planning on getting Jio Fiber.<br>One more question.<br>Do you scrape the data, compress it into a zip file and send it to the user or do you just give him the python scraper to do it for himself?<br>Because I think scraping the data and sending it to the client costs unnecessary data usage when you can just give him the application",
    "Date and Time: 2021-09-27T13:32:36Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: @@kingofyoutube9318 use your data plan and see how it goes, if you don&#39;t want to get fiber right now. <br>If I am sending code, I charge much more. <br>Again, depends on your client.<br>Don&#39;t think too much. Start working and rest of the things will fall in place gradually.",
    "Date and Time: 2021-09-27T15:28:48Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @kingofyoutube9318",
    "Reply: @@codeRECODE Thank you so much.",
    "Date and Time: 2021-09-27T15:50:16Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: The concept the same. Change the year and monitor the network. Take a note of the URLs and mimic the logic in the code. Hope it helps",
    "Date and Time: 2021-09-07T10:57:13Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Sure, will add to my list",
    "Date and Time: 2021-05-25T07:43:29Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: More coming up this week.",
    "Date and Time: 2021-05-19T08:43:19Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Oh. You may want to consider CSS Selectors. They are equally good in <b>most</b> cases. I published videos on both XPath and CSS selectors.",
    "Date and Time: 2021-05-06T07:50:52Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Yes, quite a lot for many many projects :-)",
    "Date and Time: 2021-04-20T05:45:55Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Not really. I am more of a documentation, videos, and real-life practical examples person. I still practice a lot of freelance jobs, even if I am not going to get paid for it. Practice makes a man better.",
    "Date and Time: 2021-04-20T05:44:37Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @kingofyoutube9318",
    "Reply: @@codeRECODE I&#39;ve been asking a lot of people whether to read books or the docs. A few of them said that books are great, but a lot of them said docs are better than books if I want to learn something deeply. It takes time, but I would be better than the average.",
    "Date and Time: 2021-04-20T05:51:04Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Docs are good for reference, or when you are looking for something specific. <br>As a beginner, you need to start with a book or a video course, whatever works for you. For some people, books work better, for others, video courses work better. <br>Once you know the subject and want to go deeper, docs will be place to go for reference.",
    "Date and Time: 2021-04-20T06:16:57Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Depends on the client.<br>Some would need CSV, some would need EXCEL, some need the code files, and some need it to be deployed on their personal PC /  Linux server (ssh access). Some want it user interface where they can click Run Now.<br>Better to get the clarified at the beginning and give a quote accordingly.",
    "Date and Time: 2021-04-10T10:15:08Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @acechristopher7882",
    "Reply: @@codeRECODE thanks for the detailed answer appreciate it a lot. Looking forward for more tutorials. Thanks!",
    "Date and Time: 2021-04-10T10:37:32Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Awesome! Thank you for writing detailed comment. I will try to upload the updated video for nfl.",
    "Date and Time: 2021-02-14T07:13:24Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @demianjennings2801",
    "Reply: @@codeRECODE I&#39;m not sure what you can do. They have changed their site, to where they are providing less stats. Pulling stats is what got me into scraping in the first place. You would probably have too find a completely new site like <a href=\"https://www.pro-football-reference.com/\">https://www.pro-football-reference.com/</a>.  Either way I got a lot of value from the video as it is.",
    "Date and Time: 2021-02-14T17:06:21Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-01-12T12:19:24Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: That means that you have been blocked by the web site because you were sending too many requests.<br>Rule of thumb: Do not harm the website by sending too many requests.<br>Easiest way to do this: use AutoThrottle in scrapy",
    "Date and Time: 2020-10-07T09:28:14Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @chanakya5615",
    "Reply: @@codeRECODE  I tried sir but same error was coming. I was actually scraping <a href=\"https://www.matchesfashion.com/intl/mens/shop/shoes\">https://www.matchesfashion.com/intl/mens/shop/shoes</a>     and this(429) error was coming. Pls help me with this.",
    "Date and Time: 2020-10-07T15:28:45Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: This is actually a good thing! Changing websites mean they need someone to change code = more work :-)",
    "Date and Time: 2020-09-03T04:37:54Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @ruwannishanthe3538",
    "Reply: @@codeRECODE yes..true.<br>I am trying to replicate the tutorial using <a href=\"https://www.footballdb.com/players/current.html\">https://www.footballdb.com/players/current.html</a> ...<br>Looks good",
    "Date and Time: 2020-09-03T04:55:54Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: recaptcha or human captcha are impossible to solve. Check 2captcha.",
    "Date and Time: 2020-07-07T08:07:50Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @madhavasai9098",
    "Reply: @@codeRECODE someone said using headers we can solve but I don&#39;t I don&#39;t know how to use is that possible with headers, user agent",
    "Date and Time: 2020-07-07T09:19:29Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: You are most welcome",
    "Date and Time: 2020-07-01T10:47:10Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Wider audience understands English. Still, will add hindi  to my list. Thanks",
    "Date and Time: 2020-06-25T03:50:08Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: You may want to take a look at their API",
    "Date and Time: 2020-05-04T09:19:46Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @mdshamiul358",
    "Reply: @@codeRECODE sir , it makes me crazy about learning scrapy when i see you tutorial...sir , may Almighty bless you..give more upwork related scrapy small projects ..so that we can learn by project..",
    "Date and Time: 2020-05-04T09:24:31Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: @@mdshamiul358 Please join the free course if you already haven&#39;t. As of now, I am working on an advanced course that will have many more practical examples. Good luck!",
    "Date and Time: 2020-05-04T09:28:35Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it",
    "Date and Time: 2020-04-30T00:56:42Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: Move  yield inside the for loop.",
    "Date and Time: 2020-04-27T23:32:10Z",
    " ",
    "Video Id: r9-bRxaYhaU",
    "Replier Name: @codeRECODE",
    "Reply: You would need to use google map API.",
    "Date and Time: 2020-04-27T23:33:22Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Scrapy runs as standalone executable. It wont work with google collab or jupyter notebook.",
    "Date and Time: 2021-10-07T07:00:45Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: When you send all headers, the request looks like it is coming from a real browser.",
    "Date and Time: 2021-08-02T16:19:15Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Most probably you are getting captcha challenge. You can debug the response by using open_in_browser or simply dumping the response.text to a local file for few pages to confirm this. Here are few things you can try:<br>1. try tweaking download_delay in settings.\u00a0<br>2. Try rotating user agents<br>3. Finally, use proxies",
    "Date and Time: 2021-07-13T05:59:37Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @muhammadzaman7719",
    "Reply: @@codeRECODE Wow, great it works now. Thanks a lot!",
    "Date and Time: 2021-07-15T05:35:29Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Yes it&#39;s possible. But I am staying away from all kinds of social media scraping :-)",
    "Date and Time: 2021-06-30T09:32:59Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: I just cloned the repo and ran it successfully. Check that your working directory is the one that contains the folder amazon and files <a href=\"http://runner.py/\">runner.py</a>, scrapy.cfg etc. Let me know how it goes",
    "Date and Time: 2021-04-17T09:55:26Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @David-rm1wn",
    "Reply: @@codeRECODE It works now.....thanks a lot....really appreciate it.....",
    "Date and Time: 2021-04-18T04:34:28Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @David-rm1wn",
    "Reply: @@codeRECODE I tried to do CSS selectors in zomato website but unable to find elements...any guides for that please.....Thanks alot...",
    "Date and Time: 2021-04-18T13:16:22Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Keep watching",
    "Date and Time: 2021-02-24T10:03:28Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: As soon as possible. Compiling real life examples is taking time.",
    "Date and Time: 2021-02-22T10:36:23Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Updating the comment for others. Detailed video on XPath:<br><a href=\"https://youtu.be/aHU33D0uA_E\">https://youtu.be/aHU33D0uA_E</a>",
    "Date and Time: 2021-07-13T06:00:54Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Some day :-)",
    "Date and Time: 2021-02-22T10:39:06Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @aymantareq6935",
    "Reply: @@codeRECODE eagerly waiting !! :)",
    "Date and Time: 2021-02-22T11:53:26Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @iskariotas",
    "Reply: Vpn",
    "Date and Time: 2021-02-14T20:54:37Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @ashish23555",
    "Reply: @@iskariotas how to use it.",
    "Date and Time: 2021-02-21T17:37:37Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Purchase a VPN. I recommend Vyprvpn because that&#39;s cheap and good enough. Here is the deal page - <a href=\"https://www.vyprvpn.com/buy-vpn-jan20-b\">https://www.vyprvpn.com/buy-vpn-jan20-b</a><br>Next step is to use proxies. I have posted a video on proxies on this channel  - <a href=\"https://youtu.be/qHahcxoGfpc\">https://youtu.be/qHahcxoGfpc</a>",
    "Date and Time: 2021-02-24T10:08:47Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @ashish23555",
    "Reply: @@codeRECODE thank u so much sir",
    "Date and Time: 2021-03-05T17:21:45Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-02-14T07:08:34Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Thanks \ud83d\ude42",
    "Date and Time: 2021-02-14T07:13:41Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Check what you get when you open the same URL in the browser. Then verify the headers. and most importantly, keep requests slower.  You can add DOWNLOAD_DELAY  in settings. You can experiment with this number.",
    "Date and Time: 2021-02-13T09:00:20Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @cyberbugl.d.7936",
    "Reply: @@codeRECODE Thanks for reply.<br>For test, I sent only one request (amazon homepage ). I think your very luck, it has spent several hours trying avoiding the captcha page.",
    "Date and Time: 2021-02-13T09:47:41Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @cyberbugl.d.7936",
    "Reply: In a browser, it is as usual.",
    "Date and Time: 2021-02-13T09:48:47Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: You can do that with Crawl Spiders.",
    "Date and Time: 2021-02-12T16:27:54Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: Awesome! Thank you!",
    "Date and Time: 2021-02-13T11:49:39Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: What did you try and what problems did you face?",
    "Date and Time: 2021-02-13T09:00:57Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @ibtsamahmad9582",
    "Reply: @@codeRECODE I have made one for it. Its fully dynamic and uses javascript to load content. So, i dint wanna use selenium and i checked for its Api endpoints. I found them and they used post requests. I made a scrapper in scrapy using these post requests and its fine. But the thing is that its inconsistent sometimes. I just wanted to check out what logic would u use to develop the scrapper",
    "Date and Time: 2021-02-13T09:06:58Z",
    " ",
    "Video Id: R-9UWqyFtNQ",
    "Replier Name: @codeRECODE",
    "Reply: @@ibtsamahmad9582 Good to know that you know how to find API and POST requests. You are not a beginner :-)<br>Now, coming back to your problem, if the scraper works sometimes and sometimes it doesn&#39;t work, try to find the pattern. For example, once I faced a problem where the JSON selector always broke on page 6. All websites work very differently and you just have to put in work. Good luck!",
    "Date and Time: 2021-02-13T10:11:50Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2023-01-19T08:07:54Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: in python, there is no such thing as json list. Json module helps to convert strings into python objects such as list, dictionary, depending on what the content is. As you have a list, look at he individual items to see what these contain.",
    "Date and Time: 2022-09-29T13:38:34Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: res.json() returns a list (or a dictionary)<br>To convert this to a string, you can use json.dumps()<br>Or  use response.text instead of response.json",
    "Date and Time: 2022-09-18T06:52:48Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @pythonically3107",
    "Reply: @@codeRECODE thanks for the quick reply \ud83d\udc4dlet me try this",
    "Date and Time: 2022-09-18T07:07:42Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @pythonically3107",
    "Reply: @@codeRECODE Hi , i&#39;m still facing issue why in your case it is showing &quot;dict&quot; . but in my mine it show &quot;list&quot;<br><br>&gt;&gt;&gt;data = json.loads(res.json())<br><br>TypeError: the JSON object must be str, bytes or bytearray, not list<br> <br>can you tell me proper steps to do it ? l&#39;m beginner so can understand your answer properly",
    "Date and Time: 2022-09-18T07:54:58Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Thank you!",
    "Date and Time: 2022-06-27T05:24:11Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Glad that I was able to help you. Thanks for sharing!",
    "Date and Time: 2021-12-27T12:34:33Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-10-31T11:44:05Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Can share specific examples for me to look at? <br>You can share it here but note that YouTube removes comments with links.<br>Use this page instead - <a href=\"https://coderecode.com/submit-request/\">https://coderecode.com/submit-request/</a>",
    "Date and Time: 2021-10-14T04:34:47Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Interesting idea for the next video!",
    "Date and Time: 2021-08-21T07:28:50Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: I didn&#39;t keep the CSV Haider. Why not try the code yourself?",
    "Date and Time: 2021-07-30T06:20:10Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Thank you Binayak",
    "Date and Time: 2021-07-06T03:11:33Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: You are welcome!",
    "Date and Time: 2021-07-02T05:54:32Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Thank you. Publishing a new video in few hours :-)",
    "Date and Time: 2021-04-24T12:44:08Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Notice: the JSON object must be str, bytes or bytearray, <b>not dict</b> <br>You already have a dict.<br>the purpose of using Json.loads() is to convert string to dict. And you already have a dict. Note that you don&#39;t always have to call json.loads two times. most of the time, response.json()  just works without any need of json.loads()",
    "Date and Time: 2021-04-22T12:59:51Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Thanks :-)<br>Yes, Selenium has to be the worst-case scenario, always :-)",
    "Date and Time: 2021-04-21T06:36:24Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: All the best :-)",
    "Date and Time: 2021-04-15T02:17:53Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it!",
    "Date and Time: 2021-04-14T08:49:28Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-04-14T03:37:40Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-04-14T03:38:03Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Would be happy to help but I need more details. I will also suggest you watch this video: <a href=\"https://youtu.be/97tLx_uXbCc\">https://youtu.be/97tLx_uXbCc</a>",
    "Date and Time: 2021-04-14T03:40:35Z",
    " ",
    "Video Id: tyOmc2OVZjE",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-04-14T03:40:50Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @LucLev",
    "Reply: Thanks for adding this I&#39;ve been having issues all day!",
    "Date and Time: 2023-03-10T21:17:09Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: Did pip install scrapy-playwright throw any error?",
    "Date and Time: 2023-06-27T05:04:48Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it!",
    "Date and Time: 2023-05-22T08:23:25Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: It does run with headless false on windows 10. On Windows 11, with wsl 2 it runs normally. Last option is to use virtual machones. See the follow up videos",
    "Date and Time: 2023-03-21T11:48:11Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @bbbbjjj7002",
    "Reply: @@codeRECODE it doesn\u2019t work out of the box. Why bother to fix it ?",
    "Date and Time: 2023-03-21T16:28:56Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: The simple answer is whatever gets the job done faster. <br>My workflow is to copy the request from the browser, import it to Postman, and get it working there. Then I export the code and edit it so that it works with Scrapy. If that works, that&#39;s the best thing. If it is taking longer, then I use Playwright. <br>Rendering should always be the last option unless you have a specific need.",
    "Date and Time: 2023-01-25T07:01:22Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @ASOUE",
    "Reply: @@codeRECODE Oh, awesome, thanks for the reply. I didn&#39;t know postman existed, I&#39;ll have to look into that.",
    "Date and Time: 2023-01-25T19:54:56Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: For every page, yield a request with Playwright set to True.",
    "Date and Time: 2023-01-04T04:12:37Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @hypepythonist5156",
    "Reply: @@codeRECODE do we need to wait for selector for the next page to load or can you suggest the tuts for this",
    "Date and Time: 2023-01-04T04:15:21Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: Did you run the command to install the browsers? <br>playwright install",
    "Date and Time: 2022-10-12T07:10:07Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @spotshot7023",
    "Reply: @@codeRECODE Yes, I recently found out that Playwright doesn&#39;t work in Windows. Thanks for the reply though.",
    "Date and Time: 2022-10-19T08:20:44Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: @@spotshot7023 It does work in WSL (Windows Subsystem for Linux). I tested it just now.",
    "Date and Time: 2022-10-19T10:27:53Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: Try closing the page. See Infinite Scroll with Scrapy Playwright<br><a href=\"https://youtu.be/Zk5cS7Ke3eg\">https://youtu.be/Zk5cS7Ke3eg</a>",
    "Date and Time: 2022-10-07T02:05:16Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: On Windows, Scrapy-Playwright has known issue. It will not work in headless=False mode, making it almost useless for debugging. Alternate is to use the new WSL with GUI if you are on Windows 11. For Windows 10, you will need to install Lniux on a VM. For instructions, see this video <a href=\"https://www.youtube.com/watch?v=N49wHJYHxJw\">https://www.youtube.com/watch?v=N49wHJYHxJw</a>",
    "Date and Time: 2023-02-10T11:04:58Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: So glad!",
    "Date and Time: 2022-09-29T13:34:19Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: yes, playwright needs to be True every dynamic request. <br>include page is only when you want to work directly with the page. I will cover that in upcoming videos. for now, you can ignore it. <br>good luck!",
    "Date and Time: 2022-09-24T13:29:15Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @raisulislam4161",
    "Reply: @@codeRECODE Thanks a lot sir",
    "Date and Time: 2022-09-24T15:01:18Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: <a href=\"https://youtu.be/jTKL2qTw2Rc\">https://youtu.be/jTKL2qTw2Rc</a> - This should help. Not exactly dropdown, but the concepts remain the same.",
    "Date and Time: 2022-09-21T04:26:32Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: Yes! More videos are coming up soon.",
    "Date and Time: 2022-09-20T17:26:52Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: Sure \ud83d\udc4d",
    "Date and Time: 2022-09-20T16:25:44Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @udaybhaskar999",
    "Reply: @@codeRECODE thank you soo much sir\ud83d\ude0d",
    "Date and Time: 2022-09-20T16:59:52Z",
    " ",
    "Video Id: VDpi9cwgiR8",
    "Replier Name: @codeRECODE",
    "Reply: Thanks",
    "Date and Time: 2022-09-20T16:26:03Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @codeRECODE",
    "Reply: Send that to crawl()",
    "Date and Time: 2023-03-21T11:49:04Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @codeRECODE",
    "Reply: You can\u2019t and shouldn\u2019t. <br>Scrapy works asynchronously, and that\u2019s why it\u2019s powerful. Keep item sorting logic outside your scraping.",
    "Date and Time: 2023-02-07T03:09:56Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @jaeminpark3113",
    "Reply: My method of closing spider is &#39;raise CloseSpider()&#39; with &#39;CLOSESPIDER_ERRORCOUNT&#39; : 1 in the custom_settings",
    "Date and Time: 2023-01-01T20:00:50Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @codeRECODE",
    "Reply: Even on Windows, venv is created where you execute the python -m venv venv<br>If you are using conda create, that is a completely different package. In that case, it will be in c:\\users\\&lt;you&gt;\\anconda (or something similar) folder.",
    "Date and Time: 2022-12-05T07:08:47Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @pythonically3107",
    "Reply: @@codeRECODE ohh.. I missed it.. so now If I want to create a separate venv for any project I need to create venv  ... like the above command right .? ie :<br> $ python -m venv venv",
    "Date and Time: 2022-12-05T07:15:32Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @pythonically3107",
    "Reply: Now working fine",
    "Date and Time: 2022-10-20T17:20:39Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @codeRECODE",
    "Reply: Probably settings are missing.  Review the video at <a href=\"https://www.youtube.com/watch?v=D22QqJ18rFg&amp;t=2m30s\">2:30</a>.",
    "Date and Time: 2022-10-20T17:23:53Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @pythonically3107",
    "Reply: @@codeRECODE I have resolved, it was something else. Thanks \ud83d\udc4d",
    "Date and Time: 2022-10-20T17:40:10Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @pythonically3107",
    "Reply: @@codeRECODE sir is it recommend to create separate vitual env for every project ? i saw somewhere that <br>&quot;&quot;create .venv for every project. if you create virtual env with same name(.venv) it will have no issue &quot;&quot; can you explain a little bit",
    "Date and Time: 2022-10-21T13:56:59Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @codeRECODE",
    "Reply: @@pythonically3107 Virtual environments are nothing but folders. You can not have two .venv in the same folder, but of course, you can have a folder named .venv inside as many folders as you want. I don\u2019t create a venv when I am testing out something. I use (activate) one of the few virtual environments I have. For example, I have virtual environments named ws, ml, dj, etc that I use for testing web scraping, machine learning, and Django stuff. The moment I know that I am going to spend some time on it, I create a separate virtual environment for that. <br>I hope it helps. I will create a video on this.",
    "Date and Time: 2022-10-21T14:25:15Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @codeRECODE",
    "Reply: Sure. Will add to my list.",
    "Date and Time: 2022-08-13T05:16:36Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @codeRECODE",
    "Reply: Right, that can be a pain. Adding this to my list.",
    "Date and Time: 2022-08-13T05:18:11Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @harikrishnanv6233",
    "Reply: @@codeRECODE Thank you so much",
    "Date and Time: 2022-08-13T06:47:34Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @codeRECODE",
    "Reply: Hahaha. I will take that as a compliment. <br>But no, I am not a professor. <br>You can see what I am doing at present on LinkedIn \ud83d\ude42",
    "Date and Time: 2022-08-09T13:22:44Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @mvst4u493",
    "Reply: @@codeRECODE Thank you sir . Your videos helped me a lot. I have started my career in scrapping too.",
    "Date and Time: 2022-08-09T14:23:26Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @codeRECODE",
    "Reply: Thank you. Have you tried to debug the spider? See my video on debugging if you haven&#39;t",
    "Date and Time: 2022-08-08T11:01:28Z",
    " ",
    "Video Id: D22QqJ18rFg",
    "Replier Name: @shashwatpandey10",
    "Reply: @@codeRECODE yes, I have checked those videos as well still throwing 403 error for the ticketmaster website. Please help me with the same.",
    "Date and Time: 2022-08-08T11:37:24Z",
    " ",
    "Video Id: K9MKrNGtBLs",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear it!",
    "Date and Time: 2022-02-09T12:27:37Z",
    " ",
    "Video Id: K9MKrNGtBLs",
    "Replier Name: @codeRECODE",
    "Reply: Thank you \ud83d\ude42",
    "Date and Time: 2021-11-28T04:40:31Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Thank you! Would subtitles in English help?",
    "Date and Time: 2023-07-31T09:31:29Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Pip install scraper-helper<br>From scraper_helper import get_header",
    "Date and Time: 2023-03-21T11:46:12Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it",
    "Date and Time: 2023-02-28T17:56:27Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Great \ud83d\udc4d",
    "Date and Time: 2023-01-19T08:09:13Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Sure! Whatever works :-)<br>This method allows me not leave the code and top of that, it contains a lot of additional helper methods. Again, it&#39;s a matter of convenience :-)",
    "Date and Time: 2022-11-04T05:07:32Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Hey, I am not sure I get your question correct. Are you talking about the case when you have a list of links and want to use the scraper_helper.headers() for each request?<br>In that case, there are multiple options. <br>You can run a loop over the list of URLs and yield scrapy.Request(url, headers=scraper_helper.headers())<br>I would prefer to modify the <a href=\"http://settings.py/\">settings.py</a> file and set the DEFAULT_REQUEST_HEADERS=scraper_helper.headers()<br>:cheers:",
    "Date and Time: 2022-11-04T05:20:18Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: I published this function and many more in scraper-helper<br><br>Run pip install scraper-helper<br><br>from scraper_helper import get_dict<br><br>headers = get_dict(\u2018\u2019\u2019<br>Paste headers from browser here<br>\u2018\u2019\u2019<br>)",
    "Date and Time: 2022-09-26T14:39:08Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Cookies are handled automatically by Scrapy. Headers is something that you need to examine",
    "Date and Time: 2022-04-08T16:02:42Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Comments with links are immediately removed by YouTube&#39;s spam filter.<br>I looked at the site and noticed that it uses Cloudflare Bot Management. This site does not want to be scraped and I am not aware about any method that can bypass this.",
    "Date and Time: 2022-01-26T12:38:16Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: In case you are curious how I figured that out, I noticed the cookie __cf_bm. I know by experience that any variation of cf in the cookies or headers means Cloudflare. In this particular case, cf is Cloudflare and bm is Bot Management.",
    "Date and Time: 2022-01-26T12:41:34Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @xSIXAX",
    "Reply: @@codeRECODE  ahhh thank you! Idk  maybe i can find a dumb solution. If i got one ill share it. This has saved me a lot of time for sure.",
    "Date and Time: 2022-01-26T13:59:27Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Open the site in incognito window, Press F12 and enter your URL. You will see that cookies will never be there in the first request. You probably need to go back one request to get the cookie and then send the targeted request.",
    "Date and Time: 2021-12-27T12:40:04Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @Hecticam",
    "Reply: @@codeRECODE Thank you!",
    "Date and Time: 2021-12-31T18:54:34Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Glad it helped!<br>By the way, I published this function and many others as package.Check out <a href=\"https://pypi.org/project/scraper-helper/\">https://pypi.org/project/scraper-helper/</a>",
    "Date and Time: 2021-09-06T09:57:30Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Scrapy runspider xyz -a inputfile=abc<br><br>And then directly use self.inputfile in your spider.",
    "Date and Time: 2021-06-01T17:23:13Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: What exactly is the problem that you are facing? Scrapy handles cookies automatically unless you turn it off.",
    "Date and Time: 2021-03-18T02:55:34Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @aggames5065",
    "Reply: @@codeRECODE I want to put the cookies manually to scrapy to use it",
    "Date and Time: 2021-03-18T06:36:03Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Error in 400 means client error. Either wrong headers or your IP blocked. If the page DOES NOT open in your browser, that means IP is blocked. If it works in browser, try sending correct headers. You can first try with <a href=\"http://httpbin.org/headers\">http://httpbin.org/headers</a> site. This will simply return all the headers that you send. Good luck",
    "Date and Time: 2021-02-28T02:32:02Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Use <a href=\"https://pastebin.com/\">https://pastebin.com/</a> to share your code",
    "Date and Time: 2021-02-24T10:01:37Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Most welcome",
    "Date and Time: 2021-01-12T12:21:00Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: Added to the list :-)",
    "Date and Time: 2020-12-18T05:21:07Z",
    " ",
    "Video Id: 0yANi5xUahk",
    "Replier Name: @codeRECODE",
    "Reply: @Ashish - Please follow the playlist or take my free course in a sequence.<br>I will be happy to look into your doubts. Provide as much information as you can - like what you are trying to install and what error it is giving. Use pastebin to share code, use <a href=\"http://pasteboard.co/\">pasteboard.co</a> or <a href=\"http://paste.pics/\">paste.pics</a> or something similar to share screenprints",
    "Date and Time: 2020-12-12T08:09:35Z",
    " ",
    "Video Id: VMdCUCBCYDQ",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that!",
    "Date and Time: 2023-08-10T13:10:31Z",
    " ",
    "Video Id: VMdCUCBCYDQ",
    "Replier Name: @codeRECODE",
    "Reply: Scrapy genspider",
    "Date and Time: 2023-05-12T03:14:37Z",
    " ",
    "Video Id: VMdCUCBCYDQ",
    "Replier Name: @codeRECODE",
    "Reply: I am glad \ud83d\ude42",
    "Date and Time: 2023-02-10T03:59:13Z",
    " ",
    "Video Id: VMdCUCBCYDQ",
    "Replier Name: @codeRECODE",
    "Reply: So nice of you",
    "Date and Time: 2022-08-29T10:54:24Z",
    " ",
    "Video Id: VMdCUCBCYDQ",
    "Replier Name: @codeRECODE",
    "Reply: Not sure I get your question, but still trying to answer:<br>1.  Use ImagePipeline to download images<br>2. Schedule your script using cron or windows scheduler to run everyday<br>3. Keep the data processing logic, e.g. the PDF logic , out of Scrapy and in a separate script",
    "Date and Time: 2022-08-07T03:12:55Z",
    " ",
    "Video Id: VMdCUCBCYDQ",
    "Replier Name: @codeRECODE",
    "Reply: Interesting! Thanks for letting me know. I will do better :-)",
    "Date and Time: 2021-12-16T03:54:47Z",
    " ",
    "Video Id: VMdCUCBCYDQ",
    "Replier Name: @codeRECODE",
    "Reply: Thanks Mario",
    "Date and Time: 2021-11-10T09:36:10Z",
    " ",
    "Video Id: VMdCUCBCYDQ",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it :-)",
    "Date and Time: 2021-11-09T04:38:16Z",
    " ",
    "Video Id: VMdCUCBCYDQ",
    "Replier Name: @codeRECODE",
    "Reply: Thank you! Cheers!",
    "Date and Time: 2021-11-09T04:38:50Z",
    " ",
    "Video Id: VMdCUCBCYDQ",
    "Replier Name: @codeRECODE",
    "Reply: Cheers!",
    "Date and Time: 2021-11-07T08:05:42Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: You can save the output using -o switch. For example, scrapy crawl laptop -o yourfile.csv",
    "Date and Time: 2023-05-22T08:25:07Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @marcossahade9369",
    "Reply: Your videos...",
    "Date and Time: 2022-10-27T00:01:54Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Good question. This is one of the solutions. Playwright is getting a lot of attention these days, though.",
    "Date and Time: 2022-08-07T03:07:14Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: So nice of you",
    "Date and Time: 2022-04-21T04:44:48Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Thank you \ud83d\ude03",
    "Date and Time: 2021-10-09T08:22:11Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: I know! Not being a native speaker, I am not great at pronunciations.<br>During my stay in the US, my coworkers told me that I just sound  &quot;foreign&quot;, and that&#39;s it. That&#39;s enough for me :-)",
    "Date and Time: 2021-09-07T11:05:35Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Happy to help",
    "Date and Time: 2021-07-13T05:50:13Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: If you know XPath, then use that - response.xpath(&#39;//xyz&#39;).get(). <br>No need to use CSS Selectors. I recommend CSS selectors for beginners. <br>I have published videos on both XPATH and CSS Selectors on this channel. Good luck!",
    "Date and Time: 2021-06-16T08:43:46Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @mingjunlim5205",
    "Reply: @@codeRECODE Btw, are u from Malaysia?\ud83d\ude05 Bcus I saw ur video using Lazada as an example and the currency is RM.",
    "Date and Time: 2021-06-16T20:29:31Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: \ud83d\ude00 Never had the pleasure of visiting Malaysia. I have moved back to India  now. <br>I used Lazada example because one student requested it",
    "Date and Time: 2021-06-17T02:00:32Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @pranavbelgaonkar8634",
    "Reply: your docker is not running",
    "Date and Time: 2022-01-14T09:47:48Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Did you try to_unicode  as the message suggests?",
    "Date and Time: 2021-05-04T08:12:21Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @jpinol2226",
    "Reply: @@codeRECODE yes sir, still it didn&#39;t work. I import from (scrapy.utils.python import to_unicode) still got the same depreciation warning.",
    "Date and Time: 2021-05-04T08:53:57Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: @@jpinol2226 share your code",
    "Date and Time: 2021-05-04T09:01:39Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @jpinol2226",
    "Reply: \u200b@@codeRECODE Hello sir, It&#39;s working fine now. The (to_unicode) method needed to have an exact encoding parameter. So I added a detect encoding function for the url.<br>However, the scrapy log will still show the deprecated warning. <br><br>code screenshot:<br><a href=\"https://i.postimg.cc/02FTjYW7/Capture.png\">https://i.postimg.cc/02FTjYW7/Capture.png</a><br><br>Thank you for replying sir.",
    "Date and Time: 2021-05-04T10:16:20Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: @@jpinol2226 Hey! Came back to this now.  This is not a correct approach. <br>I guess you are facing issues in exporting in Unicode format. Scrapy exports in UTF-8 by default, except for JSON format. See this from the documentation:<br><a href=\"https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_EXPORT_ENCODING\">https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEED_EXPORT_ENCODING</a><br><br>FEED_EXPORT_ENCODING\r<br>\r<br>\r<br>\r<br>If unset or set to None (default) it uses UTF-8 for everything except JSON output, which uses safe numeric encoding (\\uXXXX sequences) for historic reasons.\r<br>\r<br>Use utf-8 if you want UTF-8 for JSON too.",
    "Date and Time: 2021-05-25T08:06:54Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: IDE does not matter. <br>If you run scrapy startproject yourprojectname* from the terminal, it will create the complete project structure including <a href=\"http://settings.py/\">settings.py</a>",
    "Date and Time: 2021-04-22T10:18:08Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: By the way, I use VS Code and Pycharm. But again, this does not matter",
    "Date and Time: 2021-04-22T10:18:42Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @hythamaly9624",
    "Reply: @@codeRECODE Thanks a million, the video really helped me!",
    "Date and Time: 2021-04-22T13:11:57Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Thank you \ud83d\ude42",
    "Date and Time: 2021-03-30T15:18:23Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Thank you so much \ud83d\ude42",
    "Date and Time: 2021-03-15T03:28:46Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Hey, got back to this now. What was the problem?",
    "Date and Time: 2021-06-12T02:49:22Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Looks like you are able to install but not pull. Windows 10 64-bit: Pro, Enterprise, or Education (Build 17134 or later) are supported officially. Try this first.<br><b>docker login -u username</b><br>If it doesn&#39;t work, then google would be your friend. Share your findings for others :-)",
    "Date and Time: 2021-02-28T02:28:43Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Have covered proxies on my channel( <a href=\"https://youtu.be/qHahcxoGfpc\">https://youtu.be/qHahcxoGfpc</a> ) , but not with splash. ScraperAPI that I covered in my video can accept additional parameter and they will do the rendering. That would $249 plan. There are more service but almost all are more expensive. See this article for a comparison. It should give you a general idea about prices. Don;t forget to check JS Render option on the top of the page. <a href=\"https://www.scraperapi.com/compare-best-residential-datacenter-rotating-proxy-providers-for-web-scraping\">https://www.scraperapi.com/compare-best-residential-datacenter-rotating-proxy-providers-for-web-scraping</a>",
    "Date and Time: 2021-02-22T10:44:22Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Check the system requirements. <a href=\"https://docs.docker.com/docker-for-windows/install/\">https://docs.docker.com/docker-for-windows/install/</a><br>You already have Win Pro, otherwise for Home the instructions are here:  well <a href=\"https://docs.docker.com/docker-for-windows/install-windows-home/\">https://docs.docker.com/docker-for-windows/install-windows-home/</a>",
    "Date and Time: 2021-02-13T11:49:32Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-02-13T11:51:08Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Looks like the page is taking longer to load. Try adding wait to splash request - yield SplashRequest(url, args={&#39;wait&#39;: 5})",
    "Date and Time: 2021-01-25T08:35:43Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @turanahmad2306",
    "Reply: @@codeRECODE  Thanks for the response. I actually use the wait however it still doesn&#39;t help to me. The code for Splash Request and the output error that I got is in the below. Please let me know if you have nay idea why this happens.<br><br>yield SplashRequest(url=absolute_url, callback=self.parse_product, magic_response=True,\r<br>                meta={&#39;handle_httpstatus_all&#39;: True}, endpoint=&#39;execute&#39;,\r<br>                args={&#39;lua_source&#39;: self.script2, &#39;wait&#39;: 25, \r<br>                    &#39;timeout&#39;: 90, &#39;resource_timeout&#39;: 10\r<br>                    })<br>This is the code for the second section. It still fails to extract all the items I ask in parse_product function. Some links works some not. The error:<br>[scrapy.downloadermiddlewares.retry] ERROR: Gave up retrying &lt;GET <a href=\"https://website.com/\">https://website.com</a><br>and <br>[&lt;twisted.python.failure.Failure twisted.internet.error.ConnectionDone: Connection was closed cleanly.&gt;]",
    "Date and Time: 2021-01-25T08:49:10Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: This is a good idea for the next video. Thanks",
    "Date and Time: 2021-01-25T08:41:33Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Why not use their API? They explicitly ban scraping, thus no plans to cover it.",
    "Date and Time: 2021-01-25T08:41:13Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that",
    "Date and Time: 2021-01-25T11:12:27Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @learncodeinbangla1852",
    "Reply: Sir,<br>I am fail to enable virtual environment. Could you please tell me how Can I do it.",
    "Date and Time: 2021-03-02T10:05:17Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Use Download_delay (<a href=\"https://docs.scrapy.org/en/latest/topics/settings.html#download-delay)\">https://docs.scrapy.org/en/latest/topics/settings.html#download-delay)</a> and Auto_throttle (<a href=\"https://docs.scrapy.org/en/latest/topics/autothrottle.html#topics-autothrottle)\">https://docs.scrapy.org/en/latest/topics/autothrottle.html#topics-autothrottle)</a>. If these two don&#39;t work, use proxies. Already covered proxies in one of my videos.",
    "Date and Time: 2021-01-25T08:38:15Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: See my video on infinite scroll",
    "Date and Time: 2021-01-14T09:47:37Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: try running docker HelloWorld sample first to see if docker installation is working. <br>docker run hello-world (This should show something like &quot;Not found locally, downloading and then Hello from docker.<br><br>If this doesn&#39;t work, check the documentation <a href=\"https://docs.docker.com/docker-for-windows/install/\">https://docs.docker.com/docker-for-windows/install/</a><br><br>Good luck!",
    "Date and Time: 2021-01-14T04:24:52Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: By the way, read the error carefully - &quot;docker client must be run with elevated privileges to connect&quot;<br>Did you try running docker with Admin rights? See this: <a href=\"https://stackoverflow.com/questions/40459280/docker-cannot-start-on-windows\">https://stackoverflow.com/questions/40459280/docker-cannot-start-on-windows</a>",
    "Date and Time: 2021-01-14T04:57:11Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: WIll try to find some samples for you.",
    "Date and Time: 2021-01-14T04:26:58Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Welcome!",
    "Date and Time: 2021-01-13T08:31:40Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that!",
    "Date and Time: 2021-01-13T08:31:48Z",
    " ",
    "Video Id: RgdaP54RvUM",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it!",
    "Date and Time: 2021-01-12T14:22:43Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: Hey, I am not sure I understand your question. Are you talking about <a href=\"https://www.youtube.com/watch?v=jTKL2qTw2Rc&amp;t=00m26s\">00:26</a> when I press F12 to bring up Developer tools?",
    "Date and Time: 2023-05-09T12:01:28Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: Payload tab was introduced in Chrome 96. Before that, you could view the same information within the Network tab.",
    "Date and Time: 2023-05-09T12:04:34Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: I don&#39;t think iPad OS is supported. You use a cloud dec environment but can&#39;t say which one.",
    "Date and Time: 2023-02-07T03:12:04Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: Coming up soon!",
    "Date and Time: 2023-05-09T12:05:44Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: I can relate to that! <br>Simply learn everything you can and use the tool that fits the scenario.",
    "Date and Time: 2023-01-29T10:53:31Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: I don&#39;t think so. We cant change how to website was designed to operate. You can send multiple requests in a loop, though.",
    "Date and Time: 2023-05-09T12:05:19Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: I am using Pycharm. <br>The basic understanding of Scrapy is required for this video. I should probably mention that in the next video, Thank you!<br>Meanwhile, you can take the free course from my site (see video description for link and coupon code).<br>Alternatively, you can also see this playlist - <a href=\"https://youtu.be/y8l14bys7Nw\">https://youtu.be/y8l14bys7Nw</a>",
    "Date and Time: 2022-10-10T09:38:02Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: Not just the link, I share the complete source code for all my videos and this one is not an exception!<br>Hope it helps you. Cheers!",
    "Date and Time: 2022-09-25T17:06:47Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: Send 30 requests in the last step with  30 dates (before parsing). You would also need to send dont_filter=True",
    "Date and Time: 2022-08-15T06:19:56Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @raisulislam4161",
    "Reply: @@codeRECODE Thanks for your reply. Could you please guide me on this? A sample?",
    "Date and Time: 2022-08-15T15:46:08Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: Interesting! Adding to my list.",
    "Date and Time: 2022-08-15T06:20:20Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @muralidhar2152",
    "Reply: @upendra Sir any update regarding above comment<br>eagerly waiting for your video",
    "Date and Time: 2022-10-11T16:42:58Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: Coming up soon!",
    "Date and Time: 2023-05-09T12:05:28Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: Welcome!",
    "Date and Time: 2022-08-13T05:15:58Z",
    " ",
    "Video Id: jTKL2qTw2Rc",
    "Replier Name: @codeRECODE",
    "Reply: Glad you enjoyed it!",
    "Date and Time: 2022-08-13T05:16:12Z",
    " ",
    "Video Id: 4dGeiYybcAc",
    "Replier Name: @A__GARV_SAXENA",
    "Reply: the data u enntred in website are mainly improtant like search query",
    "Date and Time: 2022-08-20T19:25:21Z",
    " ",
    "Video Id: 4dGeiYybcAc",
    "Replier Name: @codeRECODE",
    "Reply: That\u2019s Command prompt / Power Shell in Windows and Terminals and macOS/Unix.",
    "Date and Time: 2022-07-25T17:52:27Z",
    " ",
    "Video Id: 4dGeiYybcAc",
    "Replier Name: @A__GARV_SAXENA",
    "Reply: @@codeRECODE thank you sir you tutrial really help me. i also checked yo website too for other cources.. keep doing sir good luck",
    "Date and Time: 2022-08-20T19:24:19Z",
    " ",
    "Video Id: 4dGeiYybcAc",
    "Replier Name: @codeRECODE",
    "Reply: Glad it helped. When you click a button, the aspx sends a post request. This is called post back. Do you have something else in mind?",
    "Date and Time: 2022-06-11T15:26:12Z",
    " ",
    "Video Id: 4dGeiYybcAc",
    "Replier Name: @codeRECODE",
    "Reply: That link click is calling a JavaScript function that triggers a network activity. You can examine the network traffic to see which requests are being sent.<br>Also, asyncio is part of Python installation. Don&#39;t know why you would face any issue.",
    "Date and Time: 2022-03-03T11:56:10Z",
    " ",
    "Video Id: 4dGeiYybcAc",
    "Replier Name: @codeRECODE",
    "Reply: Happy to help \ud83d\ude42",
    "Date and Time: 2021-11-23T09:26:47Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Oh yes! It is really vast!",
    "Date and Time: 2023-08-10T13:11:53Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: See this <a href=\"https://youtu.be/LfSsbJtby-M\">https://youtu.be/LfSsbJtby-M</a>",
    "Date and Time: 2022-12-03T09:08:43Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Increase your price!",
    "Date and Time: 2022-10-10T09:45:57Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Coming soon!",
    "Date and Time: 2022-08-29T10:54:33Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @yusufrifqi5006",
    "Reply: @@codeRECODE nice! I will waiting for scrapy asyncronus program",
    "Date and Time: 2022-08-31T09:58:43Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: While CSRFtoken and sessions can be handled, I do agree that this technique does not work everywhere. <br>However, this should be the first thing that we should try. Rendering using Selenium/Playwright should be the last resort. <br>Even after that, many websites will not work, and there will be no workaround. \ud83d\ude42",
    "Date and Time: 2022-08-27T07:42:52Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Short answer - No. There are multiple techniques to scrape dynamic websites. Every site is different and would need a different technique.",
    "Date and Time: 2022-06-27T05:23:57Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Yes -- See this <a href=\"https://youtu.be/RgdaP54RvUM\">https://youtu.be/RgdaP54RvUM</a>",
    "Date and Time: 2022-04-21T04:48:32Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: This is an educational video aiming to teach how things work. For legal issues, you would need to talk to your lawyer.",
    "Date and Time: 2022-01-31T06:58:04Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Oh, I understand the confusion. I removed that part to keep the video short. Anyways, you can make it quick and easy by following these steps. <br>pip install scraper-helper <br>This library contains some useful functions that I created for my personal use and later made it open source.<br>Once you have this installed,  you can use the headers that you copied directly without formatting. Simply use the function get_dict() and send the headers in a triple-quoted string:<br><br>headers = scraper_helper.get_dict(&#39;&#39;&#39;<br>accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-<br>accept-encoding: gzip, deflate, br<br>accept-language: en-GB,en;q=0.9<br>&#39;&#39;&#39;)<br>It will also take care of cleaning up unwanted headers like cookies, content-length etc. Good luck",
    "Date and Time: 2021-11-26T06:19:50Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @ThangHuynhTu",
    "Reply: @@codeRECODE Really nice. Thanks for your clarifying!",
    "Date and Time: 2021-11-26T07:04:15Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Yes it will.<br>See my many videos on POST requests - <a href=\"https://www.youtube.com/c/CodeRECODE/search?query=post\">https://www.youtube.com/c/CodeRECODE/search?query=post</a>",
    "Date and Time: 2021-11-20T04:04:07Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: It&#39;s really hard to calculate how many GBs your project is going to consume. If you can probably run your project on any of the cloud services.<br>For any serious work, I would suggest to get a broadband connection with no data cap.",
    "Date and Time: 2021-11-16T10:43:10Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @arunk6435",
    "Reply: @@codeRECODE Thank You, Mr Upendra. I would like to know what data plan you use. What is your daily Data Limit?",
    "Date and Time: 2021-11-22T14:02:38Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Nothing changes. JSON and XHR is just browser&#39;s way of logically grouping information in this case.",
    "Date and Time: 2021-10-26T08:40:34Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Find the API key and add it to headers",
    "Date and Time: 2021-10-13T06:00:16Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: You can send Post requests.",
    "Date and Time: 2021-10-13T06:06:03Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: You can increase the CONCURRENT_REQUESTS from default 16 to a higher number.<br>In most cases, you will need proxies if you want to scrape faster.",
    "Date and Time: 2021-09-21T08:32:36Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Thank you",
    "Date and Time: 2021-09-02T19:29:06Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Try this - open network tab. Reload the site. Once the page is loaded, press control F / Cmd F while the network tab is active. Now search for any text on the page that you need. It will take you to the exact URL where this data is being loaded from.",
    "Date and Time: 2021-08-31T11:44:02Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Glad it helped",
    "Date and Time: 2021-06-18T04:55:13Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Yes, I have covered this in many videos. I am planning to do a dedicated video on pagination.",
    "Date and Time: 2021-06-14T04:04:32Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @stalluri11",
    "Reply: @@codeRECODE look forward to it.  I can&#39;t find a video on this",
    "Date and Time: 2021-06-14T04:12:57Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that",
    "Date and Time: 2021-06-14T04:04:39Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Open dev tools and check the network tab. See what happens when you click search.<br><br>If you can&#39;t figure it out, use selenium",
    "Date and Time: 2021-06-08T10:03:33Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Glad it helped :-)",
    "Date and Time: 2021-06-07T09:04:25Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-05-25T07:43:39Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Nothing changes! All, JS, XHR is Chrome&#39;s way of organizing URLs. You will find every under the All tab as well. Just use the same technique.",
    "Date and Time: 2021-04-21T06:35:30Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: It means that the string that you are trying to load with json is not in the form of valid json format. It may need some clean up",
    "Date and Time: 2021-04-22T12:25:59Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @adityapandit7344",
    "Reply: @@codeRECODE yes sir the error has been resolved. Now can you give me an idea how can I link scrapy with django. It will be very greatful.sorry I am asking too many questions. But I M doing it practically that&#39;s why I M facing these problems.",
    "Date and Time: 2021-04-22T12:45:18Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Please watch the XPath video I posted. That will help you. It will be something like this:<br>//script[@type=&quot;application/ld+json]&quot;",
    "Date and Time: 2021-04-19T05:27:10Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @adityapandit7344",
    "Reply: @@codeRECODE yes it&#39;s but it&#39;s the second script tag in this page how can we mention the second one",
    "Date and Time: 2021-04-19T05:42:36Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: just add [2]",
    "Date and Time: 2021-04-19T06:49:32Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @adityapandit7344",
    "Reply: @@codeRECODE where can I add 2 can you tell me",
    "Date and Time: 2021-04-19T06:55:50Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Create a regular scrapy request for the url that contains the json data. In the Call back method (for example, parse) you can access the json directly using response.json() in the newer versions",
    "Date and Time: 2021-04-15T14:51:22Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @adityapandit7344",
    "Reply: @@codeRECODE hi sir have you posted any video on it?",
    "Date and Time: 2021-04-15T15:22:59Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Cheers!",
    "Date and Time: 2021-04-05T05:17:32Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: If same structure means same selectors for all those domains, just add them to start_urls or create a crawl spider.",
    "Date and Time: 2021-04-03T05:46:29Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Share your code. Usually blank strings work.",
    "Date and Time: 2021-04-03T05:50:36Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Glad that my videos are helpful :-)",
    "Date and Time: 2021-03-27T08:24:38Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Thanks for the sub!",
    "Date and Time: 2021-03-17T07:56:07Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: I have covered pagination in many videos. I am planning to create one video to cover all kind of pagination in one video.",
    "Date and Time: 2021-06-12T02:47:06Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: If your browser can handle encryption, hashing, you can do that with Scrapy too.  Most of the time, they will just send some unique key which you have to send in the next request.<br>If you don&#39;t have time to examine how it is working, you can use splash/selenium or something similar and save time.  It will be faster to code but slower in execution.<br>If you do figure out APIs, the scrapes are going to be very fast, especially when you want to get millions of items every day.<br>Finally, just think of it as another tool in your arsenal. Use the one that suits the problem at hand :-)<br>Good luck!",
    "Date and Time: 2021-03-02T09:28:05Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: I am attaching the link to the code. I just tried it and it works. Make sure that you run this with <b>scrapy runspider </b><b><a href=\"http://ntschools.py/\">ntschools.py</a></b> , not like a python script.<br>Source: <a href=\"https://gist.github.com/eupendra/7900849c56872925635d0c6c6b8f78f5\">https://gist.github.com/eupendra/7900849c56872925635d0c6c6b8f78f5</a>",
    "Date and Time: 2021-02-14T12:40:04Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @chakrabmonoj",
    "Reply: @@codeRECODE Thanks for the quick revert. What I forgot to mention is I was trying to use your code on LinkedIn. Does it have excessive privacy policies because of which it is not showing any Json file being generated? Any help appreciated.",
    "Date and Time: 2021-02-14T13:46:16Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: def process_item(self, item, spider):<br>        for field in item.fields:<br>            if item.get(field) is None: # Any other checks you need<br>                item[field]=&quot;-1&quot;<br>        return item",
    "Date and Time: 2021-01-25T11:12:03Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-01-18T09:35:43Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @mohamedbhasith90",
    "Reply: @@codeRECODE Hi sir, I&#39;m trying to scrape a website with hidden apis like you did in this video. but, the data is in POST request not in GET request like you have in the video.. I&#39;m really stuck here.. can you make a video on scraping with hidden api using POST request? i hope you find this comment",
    "Date and Time: 2023-11-27T15:43:18Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @cueva_mc",
    "Reply: Or is it possible to parse the XHR urls from python?",
    "Date and Time: 2021-01-12T21:51:54Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: I am not sure what you want to ask, can you expand your question?",
    "Date and Time: 2021-01-25T11:13:30Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Glad you like it!",
    "Date and Time: 2021-01-12T12:17:28Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: Glad it helped",
    "Date and Time: 2021-01-12T12:17:48Z",
    " ",
    "Video Id: Pu3gmdWsLYc",
    "Replier Name: @codeRECODE",
    "Reply: That&#39;s awesome!",
    "Date and Time: 2021-01-12T12:17:56Z",
    " ",
    "Video Id: 5YmyALotdn0",
    "Replier Name: @codeRECODE",
    "Reply: Thank you",
    "Date and Time: 2023-02-12T16:01:49Z",
    " ",
    "Video Id: 5YmyALotdn0",
    "Replier Name: @codeRECODE",
    "Reply: I would suggest to call the spider from VSCode or Pycharm, or any other IDE and debug directly using breakpoints.  <br>See <a href=\"https://docs.scrapy.org/en/latest/topics/practices.html#run-scrapy-from-a-script\">https://docs.scrapy.org/en/latest/topics/practices.html#run-scrapy-from-a-script</a>",
    "Date and Time: 2022-01-25T04:51:10Z",
    " ",
    "Video Id: 5YmyALotdn0",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it!",
    "Date and Time: 2021-03-27T08:23:23Z",
    " ",
    "Video Id: 5YmyALotdn0",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear it!",
    "Date and Time: 2021-01-12T12:18:04Z",
    " ",
    "Video Id: 5YmyALotdn0",
    "Replier Name: @codeRECODE",
    "Reply: There are many ways. Simplest is to add this to your spider class. This is same as -o output.csv from command line.<br><br>custom_settings ={&#39;FEED_URI&#39; : &#39;output.csv&#39;}",
    "Date and Time: 2020-11-05T11:43:36Z",
    " ",
    "Video Id: 5YmyALotdn0",
    "Replier Name: @KhalilYasser",
    "Reply: @@codeRECODE Amazing. Thank you very much.",
    "Date and Time: 2020-11-05T13:58:15Z",
    " ",
    "Video Id: 5YmyALotdn0",
    "Replier Name: @codeRECODE",
    "Reply: A common error when you are trying to run two spiders from the same script. <br>Is that what you are doing?",
    "Date and Time: 2020-11-02T09:00:17Z",
    " ",
    "Video Id: 5YmyALotdn0",
    "Replier Name: @user-vg4kj7mx2z",
    "Reply: @@codeRECODE yes thanks , im run it on pycharm and terminal , i think it is problem , thank you",
    "Date and Time: 2020-11-02T11:52:07Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: You can ignore it. In fact, if you read the message carefully, you will notice &quot;In other words, it is normal to get this warning&quot;",
    "Date and Time: 2022-12-29T11:08:47Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: Double check that your script, where you are using scraper_helper, is in the same directory where you have scrapy.cfg file",
    "Date and Time: 2022-10-28T07:12:34Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: Wow, thank you",
    "Date and Time: 2022-03-14T14:04:37Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: I am not sure if I understand your question.  Scrapy is for automating http. If you want to run it from cli, you can do that.",
    "Date and Time: 2021-10-13T06:08:37Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @hayathbasha4519",
    "Reply: @@codeRECODE thanks for replying to my message<br><br><br>I am having scenario where I have to run some commands in cli for login to website once I successfully logged in then it will return me the website url<br><br><br>I am trying automate above scenario",
    "Date and Time: 2021-10-13T06:22:01Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: Reading cli arguments can be done with ArgParser<br>I have posted a video on this channel.",
    "Date and Time: 2021-10-13T06:42:49Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-09-15T06:56:51Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: Scrapy is multi threaded by default.",
    "Date and Time: 2021-09-07T16:47:17Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @ataimebenson835",
    "Reply: @@codeRECODE Is there a way to make it faster ?<br>There are 200,000 urls to send a request to. That will take about 5 days with a Download delay of 2 seconds. Is there a way to drastically reduce the amount of days ?",
    "Date and Time: 2021-09-07T16:51:17Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: As you are using download_delay, it looks like web site is not allowing faster scraping. Otherwise I would have suggested to increase the concurrent_requests. <br>In your case, looks like using proxies is the only way.",
    "Date and Time: 2021-09-07T17:20:30Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @ataimebenson835",
    "Reply: @@codeRECODE I was trying to be on the safe side, that&#39;s why I used Download delay. I can remove the download delay. And  increase the concurrent request.<br><br>Which paid proxy provider do you recommend for rotating proxies with scrapy ?<br><br>The easiest to use with scrapy",
    "Date and Time: 2021-09-07T17:27:09Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: If your budget allows it, go with Zyte. These are the guys who made scrapy. Second best choice is scraperapi<br>Check my video on proxies to get an idea",
    "Date and Time: 2021-09-07T17:43:42Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: Thanks for watching!",
    "Date and Time: 2021-07-14T09:32:46Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-07-14T09:32:50Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-07-13T05:46:34Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @tubelessHuma",
    "Reply: It is ok and readable. Thanks for your effort.\ud83d\udc4d",
    "Date and Time: 2021-07-12T20:28:15Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @dmitrymitrofanov3920",
    "Reply: Hello, every thing ok. Thank you for video.",
    "Date and Time: 2021-07-12T20:56:29Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @gcu1",
    "Reply: I didn&#39;t even notice that the text was smaller.  The readability is perfectly fine.  And the content was terrific as usual.  Yours is the best web scraping channel on Youtube (or anywhere else for that matter).  I&#39;m looking forward to the master class update!  And one more thing....Scrapy FTW!!!!!!!!!!!",
    "Date and Time: 2021-07-12T22:39:29Z",
    " ",
    "Video Id: qQDB6SE0a9c",
    "Replier Name: @codeRECODE",
    "Reply: If you mean web development, it is in the pipeline. Will take couple of months though.",
    "Date and Time: 2021-07-12T17:43:28Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Happy to hear that! So you are using Python OR JS?",
    "Date and Time: 2021-10-10T03:31:26Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @Pylogicx",
    "Reply: @@codeRECODE Sir I&#39;m using python and waiting for the next tutorial. Your teaching method is very easy to understand. Please upload the next video of this tutorial series.",
    "Date and Time: 2021-11-13T14:36:12Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: @@Pylogicx Thank you :-)<br>Uploading one today.",
    "Date and Time: 2021-11-15T08:59:21Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Great to hear!",
    "Date and Time: 2023-08-29T15:54:05Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Web scraping with Go is a good idea. Not sure about Go with Playwright.<br>There is a Playwright  for Go - <a href=\"https://pkg.go.dev/github.com/mxschmitt/playwright-go\">https://pkg.go.dev/github.com/mxschmitt/playwright-go</a><br>It&#39;s not official though. Officially supported languages are JS, Python, Java and C#",
    "Date and Time: 2023-01-29T10:56:04Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @a4e69636b",
    "Reply: @@codeRECODE I was able to start using Playwright with Go by translating your Python code to Go.",
    "Date and Time: 2023-01-29T19:15:46Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Sure I will",
    "Date and Time: 2023-01-29T10:56:10Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Awesome, thank you!",
    "Date and Time: 2023-01-29T10:57:13Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Run this and see if this works - <a href=\"https://github.com/coderecode-com/playwright_sync_api_intro/blob/main/quotes.py\">https://github.com/coderecode-com/playwright_sync_api_intro/blob/main/quotes.py</a><br>If this doesn&#39;t work, try another browser. For example, for firefox, change line 6 to the following<br>```<br>browser = p.firefox.launch(headless=False)<br>```",
    "Date and Time: 2022-11-28T04:31:20Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it!",
    "Date and Time: 2022-10-28T03:38:29Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2022-08-13T05:16:07Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: I did a google search with your error and this is what I got:<br>1.  Reported here <a href=\"https://github.com/microsoft/playwright/issues/5636\">https://github.com/microsoft/playwright/issues/5636</a><br>2. Solution here: <a href=\"https://playwright.dev/docs/browsers#install-behind-a-firewall-or-a-proxy\">https://playwright.dev/docs/browsers#install-behind-a-firewall-or-a-proxy</a>",
    "Date and Time: 2022-05-10T03:55:29Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @AnirudhGarg1123",
    "Reply: Yes",
    "Date and Time: 2022-05-01T03:28:09Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Somehow missed replying to this. Yes, webkit does work on Windows.",
    "Date and Time: 2022-10-21T11:07:00Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Yes, I need to get to it soon. Thanks for sharing your interest :-)",
    "Date and Time: 2022-03-03T11:57:11Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Yeah! I do plan to continue this. Thanks for the reminder :-)",
    "Date and Time: 2022-02-05T11:19:15Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Noted!",
    "Date and Time: 2022-01-21T04:04:30Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: For writing to files, the usual CSV, JSON modules can be used.<br>To extract title from all pages, visit all pages and use selectors. For this specific scenario, scrapy crawl spider is more suited though.",
    "Date and Time: 2022-01-21T04:06:53Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Thanks for the specific suggestion.<br>Yes, I have more tutorials planned around this subject.",
    "Date and Time: 2022-01-14T10:04:07Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: The error is obvious but I did not cover async  API. Will create a video on async api to help you understand the concept.",
    "Date and Time: 2021-12-30T03:32:51Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @raisulislam4161",
    "Reply: @@codeRECODE sir waiting for your video on that. I am badly stuck here.",
    "Date and Time: 2021-12-30T03:44:13Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Great point! I will post another video with a detailed comparison.",
    "Date and Time: 2021-12-16T03:53:02Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Playwright is much faster than selenium. That&#39;s the most important point. I will post another video with detailed comparison.",
    "Date and Time: 2021-12-16T03:56:51Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Best of luck!",
    "Date and Time: 2021-12-04T05:58:51Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Why replace the response? You can create a new selector object<br>from scrapy.selector import Selector<br>s = Selector(text=page.content())<br>s.xpath(&#39;&#39;).get()",
    "Date and Time: 2021-11-29T03:52:21Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Monokai Contrast with colors further customized in Settings",
    "Date and Time: 2021-11-23T07:16:19Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Very Soon.",
    "Date and Time: 2021-11-13T14:53:02Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Sure. More videos coming up soon",
    "Date and Time: 2021-10-13T06:06:28Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Sure.",
    "Date and Time: 2021-10-11T14:30:16Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Use usual python libraries like csv, etc.",
    "Date and Time: 2021-10-13T06:12:32Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Thank you so much for your kind words. This is exactly why I make these videos. \ud83d\ude42",
    "Date and Time: 2021-10-11T03:14:28Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @jagdish1o1",
    "Reply: @@codeRECODE please if possible create some tutorials for scrapy and playeright together.",
    "Date and Time: 2021-10-11T11:26:03Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Will post this soon \ud83d\ude42",
    "Date and Time: 2021-10-11T03:13:25Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: More to come soon.",
    "Date and Time: 2021-10-10T10:32:53Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: This is definitely a good alternative, especially for those who don&#39;t know JS and for those who need multiple Browsers support.",
    "Date and Time: 2021-10-10T04:28:29Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Interesting! Good to see interest in Java \ud83d\ude03",
    "Date and Time: 2021-10-10T05:08:45Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: I am seriously considering this. Thanks for the feedback \ud83d\ude42",
    "Date and Time: 2021-10-09T19:27:19Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Definitely! More to come soon \ud83d\ude42",
    "Date and Time: 2021-10-09T19:27:43Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Thank you \ud83d\ude42",
    "Date and Time: 2021-10-09T19:26:51Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @sheikhakbar2067",
    "Reply: Hi, could you direct me to a tutorial explaining how to use VPN with Selenium? I am scraping a website that&#39;s blocked in my country! \ud83d\ude41",
    "Date and Time: 2021-10-09T15:27:43Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: Proxies can be used with Playwright. VPN would be at OS level. The biggest win for Selenium is the community support.",
    "Date and Time: 2021-10-09T15:28:19Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: @@sheikhakbar2067 use any vpn. I recommend vyprvpn because it&#39;s cheap.<br>VPN is not at browser level but machine level. Once you connect to VPN, all apps including selenium will use VPN",
    "Date and Time: 2021-10-09T18:05:35Z",
    " ",
    "Video Id: CK6MWehq7vI",
    "Replier Name: @codeRECODE",
    "Reply: @@sheikhakbar2067 <a href=\"https://www.vyprvpn.com/buy-vpn\">https://www.vyprvpn.com/buy-vpn</a><br>Less than 2$ a month if you take long term plan.",
    "Date and Time: 2021-10-09T18:07:15Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: html2text library can help",
    "Date and Time: 2021-06-09T04:26:55Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: <a href=\"https://coderecode.com/contact-us/\">https://coderecode.com/contact-us/</a>",
    "Date and Time: 2021-06-04T13:01:45Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it",
    "Date and Time: 2021-06-01T17:23:39Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it",
    "Date and Time: 2021-06-01T17:25:14Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: Soon \ud83d\ude42",
    "Date and Time: 2021-06-01T17:25:27Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: Speed! Scrapy is asynchronous by design. I have played around with requests, requests.session, multithreading, multitasking, and scrapy beats every approach in terms of speed.",
    "Date and Time: 2021-05-26T08:11:04Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @heisenbergwhite5845",
    "Reply: @@codeRECODE okay got it<br>Thank you!",
    "Date and Time: 2021-05-26T08:29:57Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: I ran a quick benchmark: Here are the results with 85 requests WITHOUT writing to file:<br><br># Total pages: 85\r<br># Requests Module No optimization - 85 links in 95.53 seconds\r<br># Requests Module with 32 Threads -  85 links in 16.49 seconds\r<br># Requests Module with 8 Core Multiprocessing -  85 links in 16.42 seconds\r<br># Scrapy -  85 links in 10.96 seconds<br><br>Source code: <a href=\"https://gist.github.com/eupendra/f50e752d10f6d83ad292b4a2b610efb3\">https://gist.github.com/eupendra/f50e752d10f6d83ad292b4a2b610efb3</a>",
    "Date and Time: 2021-05-26T08:46:46Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @heisenbergwhite5845",
    "Reply: @@codeRECODE Really detailed answer!<br>Thank you very much!!<br>I want to learn everything about scrapy.<br>Can you please tell me how to get started?",
    "Date and Time: 2021-05-26T09:02:23Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: @@heisenbergwhite5845 <a href=\"https://www.youtube.com/watch?v=y8l14bys7Nw&amp;list=PLj4hN6FewnwrimhTJzAtKz22t1DWQa57q\">https://www.youtube.com/watch?v=y8l14bys7Nw&amp;list=PLj4hN6FewnwrimhTJzAtKz22t1DWQa57q</a>",
    "Date and Time: 2021-05-26T09:13:22Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: Thanks :-)",
    "Date and Time: 2021-05-26T08:54:00Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: Thank you",
    "Date and Time: 2021-05-26T08:53:47Z",
    " ",
    "Video Id: 4UMh9Z7DPsw",
    "Replier Name: @codeRECODE",
    "Reply: Yes, I have been thinking about it for some time now.  :-)",
    "Date and Time: 2021-05-26T08:53:40Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: You can send scrapy.Request with methot POST or a FormRequest. I have few videos on this channel. Have a look.",
    "Date and Time: 2023-03-15T12:44:33Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: See this: <a href=\"https://youtu.be/4dGeiYybcAc\">https://youtu.be/4dGeiYybcAc</a>",
    "Date and Time: 2022-02-24T03:18:59Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: Press F12, open Network tab, clear everything and then scroll to load more pages. It will trigger the call to the API link.  This API call is something that you can recreate using Scrapy.<br>Hope it helps.",
    "Date and Time: 2022-01-26T07:34:57Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: Thanks ken",
    "Date and Time: 2021-05-25T07:42:38Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: Glad you like them!",
    "Date and Time: 2021-03-31T08:45:34Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that!",
    "Date and Time: 2021-02-13T11:50:59Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @UpendraSinghai",
    "Reply: Of course!  This is a simplified site aimed at learning the basics.<br>All sites are different, involving different methods, but the basic idea remains the sme - there will be some async request to an API. Response may or may not be json.  Most of the times you should be able to parse the response in your spider. <br>Good luck!",
    "Date and Time: 2020-10-30T16:18:49Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @LOL-cs9zo",
    "Reply: @@UpendraSinghai You doing great. Thanks for the reply.",
    "Date and Time: 2020-10-30T16:58:11Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: &quot;scrape only those posts containing a particular word&quot; -&gt; check for the word in your parse and ignore or yield based n your criteria<br>&quot;scrape only those posts which are between x and y dates&quot; -&gt; depends on the specific site, where is the date, hows site structure etc. You will have to write code accordingly.",
    "Date and Time: 2020-09-11T07:33:14Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: Interesting idea! I wonder if there are others who want something like this.<br>For you, I have a few tips. Register yourself as a freelancer on upwork, guru, freelancer, etc, and start taking on the jobs for practice. Once you start feeling comfortable, start applying. Always customize your cover letter. Always have a good profile with projects to showcase, even if you did them for learning. Takes some time so don&#39;t get discouraged quickly. Good luck!",
    "Date and Time: 2020-08-19T07:40:08Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @zangruver132",
    "Reply: @@codeRECODE thanks! And I do believe you can make a good video on this topic because the videos that comes up on searching these are of people who actually don&#39;t know web scraping and just uses extensions or gimmicks to actually do their scraping jobs.<br>For bigger projects like what you do, those gimmicks won&#39;t work, programming will, for which I only found your videos to be technical and to the point.<br>Thanks for the reply!",
    "Date and Time: 2020-08-19T07:44:43Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: @@zangruver132 Thank you!",
    "Date and Time: 2020-08-19T07:53:59Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: When you create scrapy.Request(), the default method is GET. Just add another parameter method, and set it to POST<br>scrapy.Request(url, method=&#39;POST&#39;)<br>Here is the documentation link: <a href=\"https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request.method\">https://docs.scrapy.org/en/latest/topics/request-response.html#scrapy.http.Request.method</a>",
    "Date and Time: 2020-08-18T05:24:51Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: It will be the same! Instead of scroll, just click on Load More and examine the Network XHR requests",
    "Date and Time: 2020-08-18T05:25:38Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: Thank you",
    "Date and Time: 2020-07-30T02:08:13Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @codeRECODE",
    "Reply: Vishal, I have paid course on my site. Meanwhile, I am trying to be more consistent and post a video once a week on YouTube :-)",
    "Date and Time: 2020-07-22T03:45:59Z",
    " ",
    "Video Id: aPpKjhP1r58",
    "Replier Name: @engineerbaaniya4846",
    "Reply: @@codeRECODE Okay.",
    "Date and Time: 2020-07-24T03:33:44Z",
    " ",
    "Video Id: LfSsbJtby-M",
    "Replier Name: @codeRECODE",
    "Reply: Yes, will get it to it sometime.",
    "Date and Time: 2022-08-20T16:20:58Z",
    " ",
    "Video Id: LfSsbJtby-M",
    "Replier Name: @codeRECODE",
    "Reply: meta is used by Scrapy internally for many things. People also started using meta for stuff like this. This can break things if you use the same dictionary key that is used internally. <br>So Scrapy introduced cb_kwargs to make things easier.<br>You will see meta used in older code samples.",
    "Date and Time: 2022-08-18T14:43:01Z",
    " ",
    "Video Id: LfSsbJtby-M",
    "Replier Name: @nikhilkumar-mz8jo",
    "Reply: @@codeRECODE oh. I got it.  Thank you sir for the explanation.",
    "Date and Time: 2022-08-18T17:12:16Z",
    " ",
    "Video Id: Z2yofe26K88",
    "Replier Name: @codeRECODE",
    "Reply: Happy to hear that!",
    "Date and Time: 2023-02-07T03:10:21Z",
    " ",
    "Video Id: CmIsvAYU-yk",
    "Replier Name: @codeRECODE",
    "Reply: If you don&#39;t need to store in S3, then download to a local drive. <br>S3 is suitable if you are using Scrapy Cloud or something similar that needs a cloud storage.",
    "Date and Time: 2023-02-16T13:23:21Z",
    " ",
    "Video Id: CmIsvAYU-yk",
    "Replier Name: @bbbbjjj7002",
    "Reply: @@codeRECODE  thats what im talking about. i do need to store in the cloud. but then i need to easily download entire archive to pass to the client.",
    "Date and Time: 2023-02-16T13:26:28Z",
    " ",
    "Video Id: CmIsvAYU-yk",
    "Replier Name: @codeRECODE",
    "Reply: Of course. Scrapy makes it easy by providing placeholder code. <br>If you want to use selenium alone, you will have to write more code.",
    "Date and Time: 2022-04-27T10:24:13Z",
    " ",
    "Video Id: CmIsvAYU-yk",
    "Replier Name: @codeRECODE",
    "Reply: Customize the pipeline so that you control the file name of the image. If you can build s3 url based on that. Use the yield to return the dictionary or item as usual.",
    "Date and Time: 2021-07-13T05:54:00Z",
    " ",
    "Video Id: CmIsvAYU-yk",
    "Replier Name: @codeRECODE",
    "Reply: Sure. Noted in the next video ideas!",
    "Date and Time: 2021-02-09T03:23:58Z",
    " ",
    "Video Id: CmIsvAYU-yk",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it!",
    "Date and Time: 2021-01-12T12:18:31Z",
    " ",
    "Video Id: CmIsvAYU-yk",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-01-12T12:20:04Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @codeRECODE",
    "Reply: You won\u2019t have access to disk. The only way to export the items is yield",
    "Date and Time: 2023-06-15T17:32:16Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @Whatever20237",
    "Reply: @@codeRECODE then is it a good idea to yield the data to a pandas df and then load it onto a sql server ?",
    "Date and Time: 2023-06-15T18:01:17Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @codeRECODE",
    "Reply: CSV is not a problem. You can export items as CSV/JSON etc. Otherwise, you can use Aws S3 feed storage.  <br>They do not have persistent storage, so any other method will be complicated.",
    "Date and Time: 2023-02-03T05:02:53Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @Daviuliano",
    "Reply: @@codeRECODE I can always download the items once a week or something like this, however, i just wanted the code to run every weekday and hence i wanted to store the data for a least a week. Also, i struggled to name the csv file dynamically with the csv export in scrapy. Do you know/Can point me out to how to do it?",
    "Date and Time: 2023-02-07T14:40:25Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @codeRECODE",
    "Reply: @@Daviuliano Again looks like a case for S3. About the CSV file names, use the FEEDS settings. You can use the current date to create the filename dynamically. After all, <a href=\"http://settings.py/\">settings.py</a> is a python file, and you can write any code you need.<br>See <a href=\"https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEEDS\">https://docs.scrapy.org/en/latest/topics/feed-exports.html#std-setting-FEEDS</a>",
    "Date and Time: 2023-02-07T15:21:32Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @codeRECODE",
    "Reply: Did you update ScrapingHub.yml file?",
    "Date and Time: 2022-11-24T07:32:39Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @pythonically3107",
    "Reply: @@codeRECODE what do you meant by update ? as I mentioned I added these two lines <br>&gt;&gt;&gt;project: 628842\r<br>&gt;&gt;&gt;requirements_file: requirements.txt",
    "Date and Time: 2022-11-24T07:47:27Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @codeRECODE",
    "Reply: Oops, missed to read that part. That looks okay.",
    "Date and Time: 2022-11-24T07:56:26Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @pythonically3107",
    "Reply: @@codeRECODE sir how can i identify that which pkg is a part of stacks ? what pakgs are already installed in zyte?",
    "Date and Time: 2022-11-25T14:20:31Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @codeRECODE",
    "Reply: See this if you haven\u2019t already <a href=\"https://support.zyte.com/support/solutions/articles/22000200400-deploying-python-dependencies-for-your-projects-in-scrapy-cloud\">https://support.zyte.com/support/solutions/articles/22000200400-deploying-python-dependencies-for-your-projects-in-scrapy-cloud</a>",
    "Date and Time: 2022-11-25T14:28:24Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @codeRECODE",
    "Reply: Selenium support is only possible if you deploy docker image on a  paid plan.  See this <a href=\"https://shub.readthedocs.io/en/stable/deploy-custom-image.html#deploy-custom-image\">https://shub.readthedocs.io/en/stable/deploy-custom-image.html#deploy-custom-image</a>",
    "Date and Time: 2022-12-29T11:11:16Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @johnme60",
    "Reply: @@codeRECODE Actually I read many forums , all of them saying &quot;scrapy won&#39;t support socks5 proxies&quot;, <br>scrapy only supports http / https, I have a collection of socks5 , I wanted to use proxy rotation technique with those in scrapy. But can&#39;t figure out a way.<br>If you have source I can read please share. I&#39;ll be very thankful to you.",
    "Date and Time: 2022-11-24T03:05:53Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @codeRECODE",
    "Reply: Unfortunately, there is no official support. There are some interesting discussions and possible workarounds. See this for example - <a href=\"https://github.com/scrapy/scrapy/issues/747#issuecomment-1186730617\">https://github.com/scrapy/scrapy/issues/747#issuecomment-1186730617</a>",
    "Date and Time: 2022-11-25T12:15:39Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @codeRECODE",
    "Reply: Happy to know that! \ud83d\ude42",
    "Date and Time: 2022-11-15T14:43:39Z",
    " ",
    "Video Id: svI32efCymU",
    "Replier Name: @codeRECODE",
    "Reply: So nice of you",
    "Date and Time: 2022-11-15T14:43:12Z",
    " ",
    "Video Id: ySZucCSWw5o",
    "Replier Name: @codeRECODE",
    "Reply: Will upload soon",
    "Date and Time: 2023-04-19T02:16:23Z",
    " ",
    "Video Id: ySZucCSWw5o",
    "Replier Name: @codeRECODE",
    "Reply: Actually yes -- that&#39;s in my list. I need to get to it soon.",
    "Date and Time: 2023-01-29T10:53:54Z",
    " ",
    "Video Id: ySZucCSWw5o",
    "Replier Name: @codeRECODE",
    "Reply: Thank you for your kind words. I have been on a break, coming back soon \ud83d\ude42",
    "Date and Time: 2023-01-25T07:02:09Z",
    " ",
    "Video Id: ySZucCSWw5o",
    "Replier Name: @codeRECODE",
    "Reply: Of course. Did a live stream a while back -- <a href=\"https://youtu.be/ONwH-7mBpqk\">https://youtu.be/ONwH-7mBpqk</a>",
    "Date and Time: 2022-11-28T14:24:39Z",
    " ",
    "Video Id: ySZucCSWw5o",
    "Replier Name: @SheikhMuhammadNawaz",
    "Reply: @@codeRECODE Nice... Can we do scrape any website using C# like Python does?",
    "Date and Time: 2022-11-28T14:32:30Z",
    " ",
    "Video Id: ySZucCSWw5o",
    "Replier Name: @codeRECODE",
    "Reply: @@SheikhMuhammadNawaz why not!",
    "Date and Time: 2022-11-28T14:35:14Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2023-08-10T13:11:30Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @codeRECODE",
    "Reply: Post the sample html that want to select",
    "Date and Time: 2023-02-27T17:40:36Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @codeRECODE",
    "Reply: Use symphony panther",
    "Date and Time: 2023-02-27T17:42:16Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @codeRECODE",
    "Reply: It&#39;s for selecting elements using XPath. Use filter() if you want to use CSS selectors",
    "Date and Time: 2022-12-12T04:44:22Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @TakuCoding",
    "Reply: @@codeRECODE okay thank you, I saw the code on GitHub the pages have a pagination and you loop through the pagination pages scrapping - what about a Spa or rather a site that has a load more button in which more content is loaded when you click on the link/button?",
    "Date and Time: 2022-12-12T05:12:19Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @ramprabath7352",
    "Reply: @@TakuCoding Hi, scrape their sitemap to get all the products of each category and finally scrape each product",
    "Date and Time: 2022-12-26T17:25:40Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @TakuCoding",
    "Reply: @@ramprabath7352 Thank you,",
    "Date and Time: 2022-12-26T18:00:54Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @codeRECODE",
    "Reply: Try running with standalone version of PHP.<br>First, open Powershell as admin and install Chocolatey. <a href=\"https://chocolatey.org/install#individual\">https://chocolatey.org/install#individual</a><br>After installing Chocolatey, run choco install php",
    "Date and Time: 2022-10-10T09:34:00Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @codeRECODE",
    "Reply: Brew install php<br>Or<br>Choco install php",
    "Date and Time: 2022-10-06T16:37:26Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @codeRECODE",
    "Reply: 1. Send headers<br>2. Scrape slowly and add random interval<br>3. Use Proxies",
    "Date and Time: 2022-07-18T12:20:44Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @quanghieuvu8527",
    "Reply: @@codeRECODE thank you, sir",
    "Date and Time: 2022-07-18T12:37:08Z",
    " ",
    "Video Id: rmGTB9-kB78",
    "Replier Name: @codeRECODE",
    "Reply: Every tool fits a different scenario. For example, It\u2019s easier to use a programming language you already know. Secondly, web scraping is frequently part of a bigger project. If you already have a PHP website then it may make more sense to use PHP for web scraping part. Otherwise, my all time favourite is Scrapy.",
    "Date and Time: 2022-07-14T17:05:53Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Great idea for the next video!",
    "Date and Time: 2022-10-04T17:01:05Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Yes, I tried that too. Selenium, in general, is not that great. I recommend Playwright now.",
    "Date and Time: 2022-08-29T11:14:05Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @urbaneplanner",
    "Reply: @@codeRECODE ok thanks!",
    "Date and Time: 2022-09-04T16:27:14Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @AlexRodriguez-do9jx",
    "Reply: @@codeRECODE could you possibly do a video on this \ud83e\udd14",
    "Date and Time: 2022-09-20T06:41:40Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: @@AlexRodriguez-do9jx the first one, out of many, coming up in few hours \ud83d\ude42",
    "Date and Time: 2022-09-20T06:48:03Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: @@AlexRodriguez-do9jx videos will be on Scrapy-playwright. Selenium is not on the list right now.",
    "Date and Time: 2022-09-20T06:49:03Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Thanks! It is actully difficult to find the perfect speed. I think fast paced recorded and edited videos do well. For details, we can have live more videos!",
    "Date and Time: 2022-06-27T05:21:42Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Sure. The function reads <a href=\"http://settings.py/\">settings.py</a> and if you don\u2019t care about those, you can ignore it",
    "Date and Time: 2022-04-26T13:28:35Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2022-02-09T12:27:30Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @nelsongomez8547",
    "Reply: @@codeRECODE hello good morning<br>I have a question.<br>Selenium and Beautifulsoup is good combination too?<br>I hope your answer",
    "Date and Time: 2022-02-09T12:37:29Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: @@nelsongomez8547 You can mix and match any tools that get the job done.<br>If you are working on a one-time script, or you are not worried about other people maintaining your script, you don&#39;t have to think much.<br><br>Personally, I recommend that you learn XPath or CSS selectors and use Selenium&#39;s find methods. You should not need beautifulsoup at all. Good luck!",
    "Date and Time: 2022-02-09T13:44:04Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Thank you! Cheers!",
    "Date and Time: 2022-01-31T06:58:08Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Thanks :-)",
    "Date and Time: 2021-11-24T13:39:20Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: So glad!",
    "Date and Time: 2021-11-18T03:19:08Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Of course! VPN is a system-wide. Once your PC is connected to a VPN, all the traffic goest through that, including Selenium and scrapy.",
    "Date and Time: 2021-11-05T04:56:52Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Assuming that you are talking about Selenium, you probably need explicit waits. Read python selenium docs about it.",
    "Date and Time: 2021-10-26T08:41:34Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: I am not sure if I understand your question. Scrapy shell, inspect_response, open_in_browser, etc. these work with or without splash. Then there is browser dev tools. Is there anything else that you need?",
    "Date and Time: 2021-10-13T06:11:04Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Thanks \ud83d\ude0a",
    "Date and Time: 2021-09-30T15:51:49Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Use any of the dynamic scraping techniques to scrape these further. Usually best is to find the API.",
    "Date and Time: 2021-09-14T04:11:47Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it",
    "Date and Time: 2021-09-09T09:30:38Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @sahillohiya7658",
    "Reply: yes true, i tried to scrap lazy loading images with splash but it did not work. now I am trying with selenium.",
    "Date and Time: 2022-03-13T06:30:46Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: You would need to locate the source of the data. Press F12 in Chrome, go to network tab, reload the page. Click anywhere in the network tab to ensure your focus is there and then press Ctrl F / Cmd F. This will open a search box on the left side of the Dev Tools. Search any text from the page. This will take you to the exact link that contains the data.<br>Also, sometimes the Next Page simple shows the data that has already been loaded. See this for example - <a href=\"https://www.youtube.com/watch?v=tyOmc2OVZjE&amp;list=PLj4hN6FewnwrQ3Soq1e2MKISnoWyPkWfB&amp;index=4\">https://www.youtube.com/watch?v=tyOmc2OVZjE&amp;list=PLj4hN6FewnwrQ3Soq1e2MKISnoWyPkWfB&amp;index=4</a>",
    "Date and Time: 2021-09-09T09:34:41Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: <a href=\"https://coderecode.com/submit-request/\">https://coderecode.com/submit-request/</a>",
    "Date and Time: 2021-10-07T07:08:37Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Thank you \ud83d\ude42",
    "Date and Time: 2021-09-06T09:55:02Z",
    " ",
    "Video Id: 2LwrUu9yTAo",
    "Replier Name: @codeRECODE",
    "Reply: Most welcome",
    "Date and Time: 2021-09-06T09:55:08Z",
    " ",
    "Video Id: 9lWN-6fS814",
    "Replier Name: @codeRECODE",
    "Reply: Always welcome",
    "Date and Time: 2022-09-29T13:38:49Z",
    " ",
    "Video Id: 9lWN-6fS814",
    "Replier Name: @codeRECODE",
    "Reply: Welcome!",
    "Date and Time: 2022-09-13T11:55:54Z",
    " ",
    "Video Id: sqwrFXLtpzQ",
    "Replier Name: @codeRECODE",
    "Reply: time and practice :-)",
    "Date and Time: 2022-10-30T09:02:31Z",
    " ",
    "Video Id: sqwrFXLtpzQ",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that :-)",
    "Date and Time: 2022-10-29T04:24:32Z",
    " ",
    "Video Id: sqwrFXLtpzQ",
    "Replier Name: @codeRECODE",
    "Reply: Thank you!",
    "Date and Time: 2022-10-27T04:30:48Z",
    " ",
    "Video Id: sqwrFXLtpzQ",
    "Replier Name: @codeRECODE",
    "Reply: Good to hear you solved it. I hope you keep learning and keep getting better every day.",
    "Date and Time: 2022-10-08T14:40:38Z",
    " ",
    "Video Id: 6KKXTlg0yTQ",
    "Replier Name: @codeRECODE",
    "Reply: I usually do that while editing. Sometimes, I used the wonderful app for macOS - ScreenBrush. I used another app on Windows, can&#39;t recall the name at the moment.",
    "Date and Time: 2023-03-28T13:57:14Z",
    " ",
    "Video Id: 6KKXTlg0yTQ",
    "Replier Name: @pink_kaju",
    "Reply: @@codeRECODE thank you. You have a gift. The way you teach, makes the concept to so easy to understand and remember.",
    "Date and Time: 2023-03-28T19:44:57Z",
    " ",
    "Video Id: 6KKXTlg0yTQ",
    "Replier Name: @codeRECODE",
    "Reply: @@pink_kaju Thank you for your kind words :-)",
    "Date and Time: 2023-03-29T04:06:41Z",
    " ",
    "Video Id: 6KKXTlg0yTQ",
    "Replier Name: @codeRECODE",
    "Reply: Welcome!",
    "Date and Time: 2023-02-27T17:40:45Z",
    " ",
    "Video Id: 6KKXTlg0yTQ",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it \ud83d\ude42",
    "Date and Time: 2023-02-12T16:02:10Z",
    " ",
    "Video Id: 6KKXTlg0yTQ",
    "Replier Name: @codeRECODE",
    "Reply: Sure \ud83d\ude42",
    "Date and Time: 2023-02-12T16:02:38Z",
    " ",
    "Video Id: 6KKXTlg0yTQ",
    "Replier Name: @codeRECODE",
    "Reply: Thank you \ud83d\ude0a",
    "Date and Time: 2023-02-12T16:02:52Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: It doesn\u2019t. All the rules execute on each page.",
    "Date and Time: 2023-05-23T23:17:49Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Scrapy crawl can follow all links and it does exclude visited links. However, every site is different, which means you have to write new code. You can write few projects and then use those as your starting point instead of a blank project. That&#39;s all however.",
    "Date and Time: 2023-04-18T10:29:04Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: The code is already there in the description.",
    "Date and Time: 2022-08-20T16:20:33Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @urbaneplanner",
    "Reply: @@codeRECODE thanks - missed that but see it now",
    "Date and Time: 2022-08-20T16:30:36Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: <a href=\"https://www.youtube.com/watch?v=YErdSlGiy48\">https://www.youtube.com/watch?v=YErdSlGiy48</a>",
    "Date and Time: 2022-05-10T04:02:02Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: That usually means that no items were scraped",
    "Date and Time: 2022-04-08T16:01:23Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @nepolianpratik9890",
    "Reply: @@codeRECODE the results from yield are showing though, only the log is missing",
    "Date and Time: 2022-04-08T16:29:59Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Thank you, Warren.",
    "Date and Time: 2022-02-22T03:30:29Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @prathamgargiitr2633",
    "Reply: what do you mean by generic spider ?",
    "Date and Time: 2023-01-30T06:52:32Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Can you share your code Yami?",
    "Date and Time: 2021-11-29T03:28:12Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @lostfsoul",
    "Reply: @@codeRECODE I fixed it , I just had to put the Rules inside the rules , thanks!",
    "Date and Time: 2021-11-29T19:36:21Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: @@lostfsoul Glad to hear that :-)",
    "Date and Time: 2021-11-30T04:54:50Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Thank you very much!",
    "Date and Time: 2021-11-05T04:55:25Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Thank you very much!",
    "Date and Time: 2021-10-26T08:43:18Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Yes. If you are creating a request, you can pass the headers as dictionary.<br>Alternatively, you can set the default_requests_headers in setting.",
    "Date and Time: 2021-10-11T14:29:36Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Thank you \ud83d\ude03<br>I actually hold back a lot of things to keep the video shorter. Otherwise, all my videos will be over 1 hour long.",
    "Date and Time: 2021-10-09T08:21:49Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Share the details on <a href=\"https://coderecode.com/contact-us/\">https://coderecode.com/contact-us/</a>",
    "Date and Time: 2021-09-27T15:31:18Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Thank you! \ud83d\ude03",
    "Date and Time: 2021-09-21T08:29:34Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: the first request will be to logging into websites. See my video on POST requests and this code - <a href=\"https://github.com/eupendra/POSTRequests\">https://github.com/eupendra/POSTRequests</a>",
    "Date and Time: 2021-09-14T04:15:18Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-09-14T04:13:45Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: No. Crawler is structured differently and is typically used for broader crawls. You can achieve the same functionality using spider, but the code will be less programmer friendly.",
    "Date and Time: 2021-09-02T19:27:42Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: The URLs are converted to absolute URLs. In most cases, you don&#39;t need to do anything additional.<br>In rare cases, you can use the process_links parameter of the Rule object to write your custom function. I will share some code soon.",
    "Date and Time: 2021-09-01T03:59:36Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Check this code - <a href=\"https://github.com/eupendra/scrapy_process_links_demo\">https://github.com/eupendra/scrapy_process_links_demo</a><br>Run it by commenting out process_links line to see the default behavior<br>Type hints are only for understanding the code. <br>Good luck and thanks for asking this question :-)",
    "Date and Time: 2021-09-01T04:44:04Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @imranhaider7231",
    "Reply: @@codeRECODE Thankyou and I have subscribed your channel. Can you make a video tutorial on this issue. Actually I am trying to handle pagination using LinkExtractor but due to relative url I cannot handle it",
    "Date and Time: 2021-09-02T11:32:07Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Thanks :-)",
    "Date and Time: 2021-07-15T04:07:19Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you found the voice clear. I am using audio technica atr2100 connected via behringer umc22 interface",
    "Date and Time: 2021-07-04T11:08:53Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @vampirekabir",
    "Reply: @@codeRECODE wow,me too,but i dont have any interface,does this improve sound quality?i get a lot of background white noice (bzzzzzzzzz) ,how do you overcome it?",
    "Date and Time: 2021-07-04T11:31:23Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: @@vampirekabir check the cables. In my case i had buzzing because of bad monitoring cable. Tweaking obs Settings also helped. Still, I am learning audio stuff. Not an expert. Good luck",
    "Date and Time: 2021-07-04T11:41:51Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-07-02T06:02:18Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @gshan994",
    "Reply: Yes correct",
    "Date and Time: 2023-01-08T17:40:10Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: -a argument_name=value and then use self.argument_name in spider",
    "Date and Time: 2021-06-01T17:24:56Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @adityapandit7344",
    "Reply: @@codeRECODE sir init M url kaise mention krna hn wo smj nhi aa rha hn",
    "Date and Time: 2021-06-01T17:26:07Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that!",
    "Date and Time: 2021-05-19T08:42:59Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Thanks for bringing this up. Will add to my list.",
    "Date and Time: 2021-05-19T08:44:00Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: This site was actually a site meant for practice so I did not slow down the scrape.<br>In real world, I would use AUTOTHROTTLE_ENABLED = True<br>If needed, adjust DOWNLOAD_DELAY <br>Last resort is proxies.",
    "Date and Time: 2021-05-19T08:46:28Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Interesting! Thanks for the suggestion. Adding it to the list.",
    "Date and Time: 2021-05-06T07:48:43Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: zillow terms-of-use prohibit scraping. I would avoid this site.",
    "Date and Time: 2021-05-04T08:13:38Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @manasgarg14",
    "Reply: @@codeRECODE can you just help me in identifying request carying data?",
    "Date and Time: 2021-05-19T23:29:48Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Google sheet idea noted to the list. For 2 times a day, you can use cron job ortask scheduler based on the OS",
    "Date and Time: 2021-05-04T08:14:27Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Interesting! Thanks for sharing.",
    "Date and Time: 2021-04-29T03:46:28Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Yes, this may look tough in the beginning. Practice it and this will become your friend :-)",
    "Date and Time: 2021-04-27T11:25:46Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: You&#39;re welcome \ud83d\ude0a",
    "Date and Time: 2021-04-26T05:51:57Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-04-26T05:52:11Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Hopefully soon :-)",
    "Date and Time: 2021-04-26T05:52:42Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: Use a blank LinkExtractor to follow all the links. Use regex in process_item to look for email address.",
    "Date and Time: 2021-04-26T05:57:03Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: All the best",
    "Date and Time: 2021-04-26T05:58:55Z",
    " ",
    "Video Id: MaPyt6dpnVY",
    "Replier Name: @codeRECODE",
    "Reply: You are welcome",
    "Date and Time: 2021-04-26T05:59:01Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @codeRECODE",
    "Reply: Try sending headers. I have a couple of videos on covering this.",
    "Date and Time: 2023-05-06T02:03:39Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @yforlost7691",
    "Reply: @@codeRECODE  Thanks man i could do more but still cant do what I want to do. Shell don&#39;t show the elements I need and for the json data I need to get request from the item page so I am a bit stucked here. Thanks a lot for such good playlists they are really helpful \u270c",
    "Date and Time: 2023-05-09T03:08:10Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that \ud83d\ude0a",
    "Date and Time: 2021-10-25T12:54:48Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @arohamart5841",
    "Reply: @@codeRECODE but I have a question and might tell me pls . So I have a code with python and I wish  to know if a website make a new List so I be notified by email and the code keep running by for loop abd requests\u2026. I am not sure if scrapy would help me to make notification faster  or no \u2026. So if yes which part or topic from scrappy  that I should search for ??? Wish my question makes sense to you \u2026 really thanks for the tutorial \u2764\ufe0f",
    "Date and Time: 2021-10-25T15:55:47Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @arohamart5841",
    "Reply: Please let me know sir . Hope to hear back from you",
    "Date and Time: 2021-10-25T21:32:46Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @codeRECODE",
    "Reply: Should work anywhere. Try entering just<br> Scrapy version<br>This will confirm of Scrapy is installed properly.",
    "Date and Time: 2021-02-13T13:03:14Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @adityapandit7344",
    "Reply: @@codeRECODE yes sir i will try again nd then will send you snapshot.",
    "Date and Time: 2021-02-13T13:06:29Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that!",
    "Date and Time: 2021-01-12T12:19:15Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @codeRECODE",
    "Reply: Thank you too!",
    "Date and Time: 2020-07-30T02:08:25Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @codeRECODE",
    "Reply: Selecting real life examples is actually difficult. Not because of technical reasons but because of legal. I try my best to avoid all the legal hassle and that makes finding real life example not easy. <br>I cover very real life examples on my courses on my website - it slightly easier have more flexibility there.<br>If you have examples to share, that would be good!",
    "Date and Time: 2020-08-29T08:00:56Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @codeRECODE",
    "Reply: Glad it helped",
    "Date and Time: 2020-07-22T03:48:16Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @codeRECODE",
    "Reply: Hi, you would need to learn Python first. Take a short course on Python. You can take up any book/course. Once you are comfortable with basic Python, then enter into web scraping. Note that you would need to have a basic knowledge of  HTML and CSS before you can do some scraping. Good luck!",
    "Date and Time: 2020-07-01T10:51:18Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @codeRECODE",
    "Reply: Thanks a lot",
    "Date and Time: 2020-04-27T23:04:15Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @osmarribeiro",
    "Reply: You can always count on me",
    "Date and Time: 2020-04-04T18:12:59Z",
    " ",
    "Video Id: y8l14bys7Nw",
    "Replier Name: @Deepakkumar-ls5zm",
    "Reply: Hi, can you help me to scrap on website",
    "Date and Time: 2020-10-09T04:49:57Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @codeRECODE",
    "Reply: Inspiring! Thank you for sharing this.",
    "Date and Time: 2022-09-30T01:43:08Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @minaabdelmalek4345",
    "Reply: Can you help me how to find a job too for web scraping. I will be so thankful",
    "Date and Time: 2022-12-27T23:19:09Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @codeRECODE",
    "Reply: You can use WSL or an Ubuntu virtual machine on Windows 10. I have already created a video on that. Also, should_abort_request is a Playwright feature.",
    "Date and Time: 2023-01-04T04:11:12Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @triott6497",
    "Reply: @@codeRECODE I see, Thanks!",
    "Date and Time: 2023-01-04T07:56:14Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @programandocomandersonsouza",
    "Reply: @@triott6497 whats the name of v\u00eddeo pls?",
    "Date and Time: 2023-01-17T17:13:53Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @codeRECODE",
    "Reply: I have covered these in various playwright videos. Check the playlist.",
    "Date and Time: 2022-12-29T11:03:47Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @mohamedbhasith90",
    "Reply: @@codeRECODE  Hi sir, is it possible to use scrapy playwright with scrapy shell to have interactive shell to debug like we usually do? and also i need to set wait for a selector to load..",
    "Date and Time: 2023-11-22T13:50:49Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @codeRECODE",
    "Reply: That means the GET request for images was not sent; thus, the images were not loaded.",
    "Date and Time: 2022-12-15T11:14:13Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @codeRECODE",
    "Reply: Interesting! let me add this to my list.",
    "Date and Time: 2022-10-27T11:43:25Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @codeRECODE",
    "Reply: Most welcome",
    "Date and Time: 2022-09-29T13:34:10Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @castilhodenys",
    "Reply: Hi Pythonically,<br>I searched a lot for this as well.. found some difficult solutions to implement with feed_export, changing the settings file..<br><br>I went on a different route (not that nice, but it works), using the Pipeline to generate a csv file with the semicolon as delimeter",
    "Date and Time: 2022-09-29T01:04:09Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @pythonically3107",
    "Reply: @@castilhodenys can you tell mn those settings in an easy way...plz I really need ..",
    "Date and Time: 2022-09-29T01:08:52Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @castilhodenys",
    "Reply: @@pythonically3107 not a beautiful solution, but it worked for me...<br>I&#39;m not a programmer =)<br>Using the itemPipelines file (need to use the <a href=\"http://items.py/\">items.py</a> as well), it creates a csv, read it with Pandas and add the scraped lines to it.. <br>Since I&#39;m always adding lines, I don&#39;t want to drop the previous file, so I always start reading the previous one.<br><br>Got this example from the Scrapy documentation. Hope it helps<br>on the <a href=\"http://pipelines.py/\">pipelines.py</a><br><br>######<br>import pandas as pd\r<br>\r<br>class SpiderPipeline:<br>\r<br>    def open_spider(self,spider): ### READ THE FILE IF IT ALREADY EXISTS\r<br>        try:\r<br>            self.df = pd.read_csv(&#39;output.csv&#39;,sep=&#39;;&#39;) <a href=\"http://www.youtube.com/results?search_query=%23sep\">#SEP</a> &quot;;&quot; IS THE SEMICOLON DELIMETER\r<br>        except:\r<br>            self.df = pd.DataFrame()\r<br>    \r<br>    def close_spider(self,spider):     \r<br>        self.df.to_csv(&#39;output.csv&#39;,index=False,sep=&#39;;&#39;) ### CREATING OR ADDING THE RESULT TO THE CSV\r<br>\r<br>    def process_item(self, item, spider): ### ADDING THE RESULTS TO THE DATAFRAME\r<br>        new_line = pd.DataFrame([item])\r<br>        self.df = pd.concat([new_line,self.df],ignore_index=True)\r<br>        return item",
    "Date and Time: 2022-09-29T12:34:31Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @codeRECODE",
    "Reply: See this for an easy solution- <a href=\"https://coderecode.com/how-to-create-a-tab-separated-file-with-scrapy/\">https://coderecode.com/how-to-create-a-tab-separated-file-with-scrapy/</a>",
    "Date and Time: 2022-09-29T13:32:20Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @codeRECODE",
    "Reply: Thank you Denys for sharing the code!",
    "Date and Time: 2022-09-29T13:33:52Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @sumitkumar-hn7rv",
    "Reply: Good Evening Sir, I learned a lot from your videos and I am very thankful to you. I want you to cover taking screenshot with different screen size and using another browser like brave in scrapy-playwright. Thank you in advance.",
    "Date and Time: 2022-09-27T15:23:33Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @castilhodenys",
    "Reply: Great videos!! Always usefull content and easy to understand! Great timing for me, since I&#39;m trying to use more and more scrapy-playwright.<br>If possible, would like to see an application where the products are loaded with the &quot;Load More&quot; button.<br>Thanks!!",
    "Date and Time: 2022-09-27T17:12:21Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @haideralihassan5053",
    "Reply: Thank you, sir. You posted a very informative video as before you do. Please share some tricks on how we can share scrapy code with clients. As many clients are unfamiliar with scrapy code and how to run it.",
    "Date and Time: 2022-09-27T18:11:36Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @SumitKumar-mk7ul",
    "Reply: Sir, I sent you help request on your website regarding taking screenshot using scrapy-playwright plugin. I tried the code given on Github repository of scrapy-playwright. Screenshot is successful but no content is showing in image. Please check my code that I have sent you. Thank you",
    "Date and Time: 2022-09-29T07:35:59Z",
    " ",
    "Video Id: 2UtLq7-rqeE",
    "Replier Name: @codeRECODE",
    "Reply: @Sumit - Your code is fine. I ran it and it works. You are probably getting banned by the site.",
    "Date and Time: 2022-09-29T13:57:12Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @legallyinsane205",
    "Reply: Just yesterday i downloaded images with custom names but i didn&#39;t use piplines .. instead i did it in a genspider body",
    "Date and Time: 2020-07-03T13:51:25Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: @@legallyinsane205 excellent. Do you want share details here? I am always Curious to learn new ways to get things done",
    "Date and Time: 2020-07-03T14:51:45Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @legallyinsane205",
    "Reply: your videos help a lot sorry the code is not formatted properly .. I just learned python and scraping in the quarantine .. I love coding and programming though am a civil engineer .. this code is for my personal construction business it downloads construction ads from that website :)",
    "Date and Time: 2020-07-03T15:13:27Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Oh I missed to reply on this one. Yes, your approach will with images and files as well. In my future videos, I will probably explain why using pipelines scales better and what are other practical uses of pipelines. Thanks for sharing",
    "Date and Time: 2020-07-10T04:31:46Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @engineerbaaniya4846",
    "Reply: Subscribed",
    "Date and Time: 2020-07-20T20:07:33Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Use file downloader pipeline.",
    "Date and Time: 2023-03-28T03:00:10Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Interesting. Let me try that myself.",
    "Date and Time: 2022-10-18T06:24:28Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Happy to help :-_",
    "Date and Time: 2022-01-31T06:56:12Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Thanks and welcome",
    "Date and Time: 2021-11-12T06:54:11Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-09-29T06:04:24Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: You&#39;re welcome!",
    "Date and Time: 2021-08-31T11:41:26Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Getting back to this now. If you haven&#39;t, watch my video on Pagination.",
    "Date and Time: 2021-08-21T08:03:20Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: XPath or CSS Selector would not make a difference. The image_urls field must be a list.",
    "Date and Time: 2021-07-29T09:39:59Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @JohnCarrFitness",
    "Reply: @@codeRECODE  thanks",
    "Date and Time: 2021-07-29T21:19:52Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Yes, I missed to mentioned that in the video. I think I should share requirements.txt file along with the code",
    "Date and Time: 2021-06-07T09:14:23Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @truverol8205",
    "Reply: you are a true lifesaver",
    "Date and Time: 2022-11-17T19:29:47Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @user-wc1kx5zr3k",
    "Reply: thanks, but for a long time I could not understand why it does not download",
    "Date and Time: 2023-07-12T11:15:00Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Yes, you are correct. I might have corrected it later on and did not include that part in the edited version. Anyways, I have been thinking about revisiting this topic. Will upload a newer version with a different site soon :-)",
    "Date and Time: 2021-05-26T08:08:27Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Covered that in the video at <a href=\"https://www.youtube.com/watch?v=jMMErSuEJ2g&amp;t=08m57s\">08:57</a>",
    "Date and Time: 2021-05-22T03:28:36Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Should work, check your spellings. its ::attr(href)<br>If it still doesn&#39;t work, post the snippet here",
    "Date and Time: 2021-05-19T08:42:23Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Just disable the pipeline. Run the spider with -o output.csv and you will have everything in csv.",
    "Date and Time: 2021-03-07T12:38:33Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that",
    "Date and Time: 2021-01-27T04:33:39Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: You are welcome!",
    "Date and Time: 2021-01-12T12:20:00Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: I am not sure I got your question correctly. If you want to store the images in different folders with every run, you will have to write the logic which creates the path. You can use timestamps in the folder name, for instance.",
    "Date and Time: 2020-10-23T11:18:39Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @ameygirdhari8703",
    "Reply: Sir could you suggest any example of it",
    "Date and Time: 2020-10-23T11:22:57Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: @@ameygirdhari8703 share your pipeline code",
    "Date and Time: 2020-10-23T11:29:44Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @ameygirdhari8703",
    "Reply: @@codeRECODE sir actually I am new to this thing,  I saw your tutorial  found insightful thats why I posted comment.  I tried the code you mentioned in the video, doesn&#39;t write any new code. Thanks for help.",
    "Date and Time: 2020-10-23T12:01:06Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it :-)",
    "Date and Time: 2020-08-29T07:49:25Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Good!",
    "Date and Time: 2020-08-18T05:27:07Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Good idea! Shared the code as github gist in my latest video (about proxy).",
    "Date and Time: 2020-08-29T07:52:09Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Share your code in pastebin or similar.",
    "Date and Time: 2020-07-25T10:20:45Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @hamidnawaz9678",
    "Reply: @@codeRECODE import scrapy\r<br>\r<br>from ..items import MensScrapperItem\r<br>\r<br>\r<br>class AustraliaScrapperSpider(scrapy.Spider):\r<br>    name = &#39;australia_scrapper&#39;\r<br>\r<br>    start_urls = [&#39;<a href=\"https://www.surfstitch.com/nz/sale/mens/clothing?start=0&amp;sz=100&#39;]\">https://www.surfstitch.com/nz/sale/mens/clothing?start=0&amp;sz=100&#39;]\r</a><br>\r<br>    def parse(self, response):\r<br>     for img in response.css(&quot;li.grid-tile&quot;):\r<br>        item = MensScrapperItem()\r<br>        item[&quot;image_urls&quot;] = [img.css(&quot;img.bottom::attr(&#39;src&#39;)&quot;).getall()]\r<br>       # item[&#39;brand_name&#39;]=img.css(&quot;.brand-name::text&quot;).getall()\r<br>\r<br>        yield item",
    "Date and Time: 2020-07-27T10:46:44Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Getall returns a list, no need to surround it in [], it will create nestled list",
    "Date and Time: 2020-07-28T16:06:30Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Thank you Vishal",
    "Date and Time: 2020-07-22T03:45:10Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Check that pipeline is enabled in settings and pipeline name is correct. If that is correct, check the image url is fetched correctly and it is past as list, not a string<br>These are the most common mistakes. let me know how it goes",
    "Date and Time: 2020-07-22T03:48:08Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: \u200b@@hajaksksnsjksksbsnsn check your logs, do you have a warning at the beginning about pillow?<br>WARNING: Disabled ImagesPipeline: ImagesPipeline requires installing Pillow 4.0.0 or later<br>If yes, run pip install pillow first. <br>This used to be an error in the earlier version of scrapy. Now it is just a warning which is often overlooked.",
    "Date and Time: 2021-07-30T12:36:30Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: @@hajaksksnsjksksbsnsn - Source code: <a href=\"https://github.com/eupendra/wiki-images-download\">https://github.com/eupendra/wiki-images-download</a>",
    "Date and Time: 2021-07-30T13:07:18Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: \u200b@@hajaksksnsjksksbsnsn In this case you should have this: [scrapy.middleware] INFO: Enabled item pipelines:<br>[&#39;scrapy.pipelines.images.ImagesPipeline&#39;]<br><br>Share your logs",
    "Date and Time: 2021-07-30T13:18:20Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: That&#39;s true. Sometimes it causes confusion between PIL and pillows . Thanks!",
    "Date and Time: 2020-07-11T06:23:17Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: You are so welcome",
    "Date and Time: 2020-07-11T05:24:32Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: More to come!",
    "Date and Time: 2020-07-06T04:22:57Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @codeRECODE",
    "Reply: Sure, will add to my list :-)",
    "Date and Time: 2020-07-06T04:23:21Z",
    " ",
    "Video Id: jMMErSuEJ2g",
    "Replier Name: @salmanrazzaq5167",
    "Reply: Thank You sir, Waiting for that..",
    "Date and Time: 2020-07-12T12:38:54Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Thank you so much! This means a lot!",
    "Date and Time: 2022-07-01T13:31:42Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @sasharadkova8574",
    "Reply: @@codeRECODE no, thank <b>you</b> :)",
    "Date and Time: 2022-07-01T15:01:52Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it!",
    "Date and Time: 2023-08-15T17:00:21Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it.",
    "Date and Time: 2023-02-01T12:37:02Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Never thought about Slack.",
    "Date and Time: 2022-03-03T12:01:21Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Glad to help",
    "Date and Time: 2022-01-14T10:04:14Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Glad that it helped",
    "Date and Time: 2021-12-27T08:59:46Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Yes, you are right! <br>When I mentioned XML being a format for exchanging data, the objective was to give a context of the popularity of XML. <br>Even around 10 years ago, it was expected from a developer that he knows XML, XPATH, XSLT and SOAP. It was the time when not everyone had moved to JSON and REST. But then, 10 years is like a century in software development :-)",
    "Date and Time: 2021-09-30T12:00:32Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-09-27T04:48:14Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: \ud83d\ude42 Thank you. I belive that shortcuts should be learnt only once we know the basics.",
    "Date and Time: 2021-04-29T03:44:33Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Please share your code",
    "Date and Time: 2021-04-22T12:24:44Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: See my video on Crawl Spider. :-)",
    "Date and Time: 2021-04-03T05:44:41Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Thanks Kartik",
    "Date and Time: 2021-04-01T06:38:41Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Thanks, Soon :-)",
    "Date and Time: 2021-03-22T08:24:31Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @abukaium2106",
    "Reply: @@codeRECODE i have a talk about your scrapy master course. Can you give me your contract mail or social media??",
    "Date and Time: 2021-03-22T15:01:49Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-03-27T08:24:49Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Added to the list \ud83d\ude42",
    "Date and Time: 2021-03-18T09:11:08Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-03-18T03:10:33Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Glad you enjoyed it!",
    "Date and Time: 2021-03-18T03:10:40Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Hope you enjoyed it!",
    "Date and Time: 2021-03-18T03:11:01Z",
    " ",
    "Video Id: aHU33D0uA_E",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that!",
    "Date and Time: 2021-03-18T03:11:05Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: Wonderful! Thank you for your kind words. Means a lot to me :-)",
    "Date and Time: 2021-08-13T07:01:19Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: Add all the sites in start_urls and domains",
    "Date and Time: 2022-09-13T12:52:11Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: You can send an argument from Scrapy command line using -a switch, read it in <i>_init_</i> and set the attributes. See <a href=\"https://doc.scrapy.org/en/latest/topics/spiders.html#spider-arguments\">https://doc.scrapy.org/en/latest/topics/spiders.html#spider-arguments</a>",
    "Date and Time: 2022-03-12T10:44:59Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: Sure. This eventual is just a way to <br>1. get all links <br>2. look for specific text in the response.",
    "Date and Time: 2021-11-26T06:13:07Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: Added to the list. Thanks!",
    "Date and Time: 2021-08-31T11:40:46Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: Missing http://",
    "Date and Time: 2021-08-14T18:17:56Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @haideralihassan5053",
    "Reply: @@codeRECODE thanks",
    "Date and Time: 2021-08-14T18:41:10Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: Happy to help :-)<br>You can write a regex to extract the phone numbers. By the way, the approach in this video works when you just want to create a list of email addresses. Or perhaps, for initially analysis to get  all the links which contain the email addresses, and then analyzing these further",
    "Date and Time: 2021-08-13T07:06:15Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @mingjunlim5205",
    "Reply: @@codeRECODE Sir, I want to ask how can I pass a few variables from other Python files to the scrapy python file that I created (same as how u create it) in this video? I am facing the error of being unable to pass variables to the crapy python file I created",
    "Date and Time: 2021-08-14T11:31:17Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: See this: <a href=\"https://github.com/eupendra/Unsplash_Scraper\">https://github.com/eupendra/Unsplash_Scraper</a><br>This has what you need. By the way, I will be covering this in this Monday&#39;s live video.",
    "Date and Time: 2021-08-14T11:47:03Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @mingjunlim5205",
    "Reply: @@codeRECODE Great. I created a CrawlSpider as what you did in this video. Just failed to pass 3 variables from another Python file to the CrawlSpider python scrapy file where I need to use the values from the 3 variables in another Python file<br><br>Do you have any other online resources or tutorials that you can share with me so that I can try them out first? \ud83d\ude05",
    "Date and Time: 2021-08-14T12:45:11Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it!",
    "Date and Time: 2021-08-13T07:02:39Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: Glad you like them!",
    "Date and Time: 2021-08-13T07:02:34Z",
    " ",
    "Video Id: nRZ2q83AG4g",
    "Replier Name: @codeRECODE",
    "Reply: Great suggestion for another video! Meanwhile, start with <a href=\"https://regexr.com/\">https://regexr.com/</a> site. It has many hints, cheatsheets and community samples.",
    "Date and Time: 2021-08-13T07:02:32Z",
    " ",
    "Video Id: 9bGzr0cHQ20",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it!",
    "Date and Time: 2023-08-10T13:10:26Z",
    " ",
    "Video Id: 9bGzr0cHQ20",
    "Replier Name: @codeRECODE",
    "Reply: Works on items, ie, whatever you yield<br>Doesn\u2019t care about static/dynamic",
    "Date and Time: 2023-02-07T16:17:54Z",
    " ",
    "Video Id: 9bGzr0cHQ20",
    "Replier Name: @codeRECODE",
    "Reply: 1. Easiest way is to store the data in a CSV and from a separate script, load the CSV to a data frame ( pd.read_csv). The general idea is to keep the data collection logic separate than data manipulation logic.<br>2. Use windows scheduler (video already posted) or Cron (video coming soon) depending on your OS",
    "Date and Time: 2022-11-08T08:08:48Z",
    " ",
    "Video Id: 9bGzr0cHQ20",
    "Replier Name: @codeRECODE",
    "Reply: you can create item or dicitonary in the first one, use the cb_kwargs to send it to the next, add more values, and finally yield from the last fucntion.",
    "Date and Time: 2022-06-27T05:19:49Z",
    " ",
    "Video Id: 9bGzr0cHQ20",
    "Replier Name: @codeRECODE",
    "Reply: Thank you! Cheers!",
    "Date and Time: 2022-02-09T12:07:03Z",
    " ",
    "Video Id: 9bGzr0cHQ20",
    "Replier Name: @codeRECODE",
    "Reply: Scrapy.Request(\u2026.,dont_filter=true)",
    "Date and Time: 2022-01-27T23:17:12Z",
    " ",
    "Video Id: 9bGzr0cHQ20",
    "Replier Name: @codeRECODE",
    "Reply: It would be hard to come up with a common approach. It differers so much with each site. If you have specific problem, may i can help",
    "Date and Time: 2022-01-31T06:55:51Z",
    " ",
    "Video Id: 9bGzr0cHQ20",
    "Replier Name: @codeRECODE",
    "Reply: You&#39;re welcome",
    "Date and Time: 2022-01-26T07:35:04Z",
    " ",
    "Video Id: 9bGzr0cHQ20",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2022-01-25T04:45:41Z",
    " ",
    "Video Id: 9bGzr0cHQ20",
    "Replier Name: @codeRECODE",
    "Reply: . means current node. It is useful when joining two XPATHs. In this video, note that I am running a loop on a selector object, not the response. I am then using. inside the for loop. This ensures that the next piece of XPath is called on only the current selector object and not on the whole list. Hope it makes sense. I highly recommend that you watch the XPath tutorial on this channel.",
    "Date and Time: 2022-01-23T07:31:15Z",
    " ",
    "Video Id: dmtHyl8nLMI",
    "Replier Name: @codeRECODE",
    "Reply: Use proxy",
    "Date and Time: 2023-06-08T12:13:37Z",
    " ",
    "Video Id: dmtHyl8nLMI",
    "Replier Name: @quanghieuvu8527",
    "Reply: @@codeRECODE thank you.",
    "Date and Time: 2023-06-08T13:39:27Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Glad it helped!",
    "Date and Time: 2023-02-03T04:58:52Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: That is true",
    "Date and Time: 2022-09-30T01:42:01Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: and that&#39;s precisely the reason I recommend getting one of the cheaper proxy providers. I will see if I can find something else, but sooner or later, they will all stop working.",
    "Date and Time: 2022-06-27T05:22:49Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Happy to help",
    "Date and Time: 2022-03-03T11:48:37Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Not sure I got the question.",
    "Date and Time: 2022-03-03T12:08:56Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: If it is a code on text message, you can use the web client for messages and read the messages.",
    "Date and Time: 2021-12-08T04:29:10Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Are you using the same code? Which proxy did you try? Or some variation?",
    "Date and Time: 2021-10-26T08:42:39Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Free proxies are really unreliable. Check scrapy-rotating-proxies package. This one can be used with a custom proxy list.",
    "Date and Time: 2021-10-26T08:46:55Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Yes, it&#39;s been in my list for some time now. Will get it to it.",
    "Date and Time: 2021-09-08T13:48:45Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @ataimebenson835",
    "Reply: @@codeRECODE Nice, would be looking forward to it. Really appreciate",
    "Date and Time: 2021-09-08T14:01:57Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: <a href=\"http://2captcha.com/\">2captcha.com</a>",
    "Date and Time: 2021-06-09T16:16:46Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @ataimebenson835",
    "Reply: @@codeRECODE Please can you make a video on how to solve recaptcha&#39;s using this ?",
    "Date and Time: 2021-09-07T10:25:12Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: \u200b\u00a0@Ataime Benson\u00a0 - solving Recaptcha is a sensitive topic. The presence of any sort of captcha means that the site is discouraging from being scraped. For <i>educational purposes</i> I can tell you that there are many services like 2captcha that can solve Recaptcha for a very small amount of money.",
    "Date and Time: 2021-09-07T10:42:11Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @ataimebenson835",
    "Reply: @@codeRECODE Thanks",
    "Date and Time: 2021-09-07T10:49:25Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Did you try running the code from the link in the description? If yes, what is the exact error you are getting?",
    "Date and Time: 2021-05-31T07:24:44Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @adityapandit7344",
    "Reply: @@codeRECODE  failed because website has a captcha for verification. Nd giving 307 error!",
    "Date and Time: 2021-05-31T10:09:21Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Will chek. Anyways you can use 2captcha kind of service to solve that",
    "Date and Time: 2021-06-01T17:26:15Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Write your code without proxy first. Once you are sure that everything is working, then add proxies.",
    "Date and Time: 2021-04-17T10:04:52Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Every HTTP Request is one API call, doesn&#39;t matter whether it is an GET, POST, or result is HTML, JS, image. Hope it helps :-)",
    "Date and Time: 2021-03-02T11:57:21Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Yes if you want to experiment and are okay with slow proxies. Any paid proxy will be lightening fast as compared to free ones.",
    "Date and Time: 2021-02-22T10:35:13Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: You\u2019re welcome \ud83d\ude0a",
    "Date and Time: 2021-01-12T12:20:11Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Thank you, my good man! :-)",
    "Date and Time: 2020-12-11T09:41:19Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @lordmelbury7174",
    "Reply: @@codeRECODE I get this, it only changes on the 5th attempt:<br><br>{<br>  &quot;origin&quot;: &quot;<a href=\"http://80.239.199.101/\">80.239.199.101</a>&quot;<br>}<br><br>{<br>  &quot;origin&quot;: &quot;<a href=\"http://80.239.199.101/\">80.239.199.101</a>&quot;<br>}<br><br>{<br>  &quot;origin&quot;: &quot;<a href=\"http://80.239.199.101/\">80.239.199.101</a>&quot;<br>}<br><br>{<br>  &quot;origin&quot;: &quot;<a href=\"http://80.239.199.101/\">80.239.199.101</a>&quot;<br>}<br><br>{<br>  &quot;origin&quot;: &quot;<a href=\"http://80.239.199.101/\">80.239.199.101</a>, <a href=\"http://207.74.82.103/\">207.74.82.103</a>&quot;<br>}<br><br>I&#39;ve checked and triple checked my code matches yours.<br>Any suggestions?",
    "Date and Time: 2020-12-11T09:48:41Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Strange!  Contact support team",
    "Date and Time: 2020-12-18T05:22:15Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Thanks Tim.<br>ML based videos are in the plans. <br>I really appreciate you brining it up though.",
    "Date and Time: 2020-10-11T05:27:19Z",
    " ",
    "Video Id: qHahcxoGfpc",
    "Replier Name: @codeRECODE",
    "Reply: Hope this helps :-)",
    "Date and Time: 2020-08-21T09:27:33Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Thanks a lot \ud83d\ude0a",
    "Date and Time: 2022-03-03T12:01:26Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Glad you enjoyed it",
    "Date and Time: 2021-10-26T08:41:48Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Sure I will",
    "Date and Time: 2021-10-14T04:31:55Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: You&#39;re very welcome!",
    "Date and Time: 2021-10-07T07:08:22Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: If the site is sending 403, that means that the site doesn&#39;t want to be scraped. I would avoid such sites. For educational purposes, what I can share is that Scrapy has a setting AUTOTHROTTLE_ENABLED  that you can set to True. You can also experiment with DOWNLOAD_DELAY. Basically, you need to slow down.",
    "Date and Time: 2021-09-29T06:07:47Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Thank you for asking Udit. Very soon. In 2 or 3 days. Got delayed because of my other commitments :-(",
    "Date and Time: 2021-09-27T04:26:57Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Most welcome!",
    "Date and Time: 2021-09-25T08:06:54Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-09-21T08:30:34Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Hello Mario, there is no single answer that fits everywhere. Every site is unique. Monitor the network traffic. See the parameters that are being sent. Try to find the source of these parameter values. It takes little bit of practice but with time you will get better. Good luck.",
    "Date and Time: 2021-09-21T08:34:47Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Thank you Carlos :-)",
    "Date and Time: 2021-09-21T08:35:04Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Thank you \ud83d\ude42",
    "Date and Time: 2021-09-14T06:17:09Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @th3falln1gaming98",
    "Reply: @@codeRECODE Sir please create video tutorial on Scrapy, using Google sheets to store data.",
    "Date and Time: 2021-09-14T06:50:13Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Soon :-)",
    "Date and Time: 2021-09-14T06:56:06Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @Littleturtle94",
    "Reply: Hi Sir, what if the api key changes every 15 minutes? Is there any way to bypass the need of using right click to copy curl, just using scrapy?",
    "Date and Time: 2021-09-14T01:41:58Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @ahmedellban5748",
    "Reply: thanks",
    "Date and Time: 2021-09-15T14:52:06Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: I just tried and it is working.<br>If you are on Windows, you will see two options when you right click on Network tab - Curl Cmd and Curl Bash (or something similar).<br>Postman can import only Curl in Bash format.",
    "Date and Time: 2021-09-13T06:59:49Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: I am also thinking about creating a video or two on creating API. Should be fun.",
    "Date and Time: 2021-09-13T04:58:05Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: You would have to find a selector that can select one row. Then run a loop over this selector to extract each &quot;celll&quot; one by one. Watch this video (at 10min mark) to get an idea - <a href=\"https://youtu.be/R-9UWqyFtNQ?t=603\">https://youtu.be/R-9UWqyFtNQ?t=603</a>",
    "Date and Time: 2021-09-13T05:03:10Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2021-09-13T05:03:29Z",
    " ",
    "Video Id: ThKiZjLNN8Y",
    "Replier Name: @codeRECODE",
    "Reply: Thank you so much \ud83d\ude00<br>Next video is about converting this code to Scrapy and downloading all these images.",
    "Date and Time: 2021-09-13T05:04:51Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: Try Pandas!",
    "Date and Time: 2023-09-17T10:03:48Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: Glad that it helped.",
    "Date and Time: 2022-03-14T14:04:32Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: Most welcome",
    "Date and Time: 2021-04-13T03:28:13Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: Scrapy is asynchronous , meaning multiple request are sent at the same time. The response are processed as they are received. It is not sequential. <br>That is actually one of the biggest strength of Scrapy.",
    "Date and Time: 2020-11-05T11:31:34Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @KhalilYasser",
    "Reply: @@codeRECODE Thanks a lot. I have already read about this powerful feature. But is there any workaround to control the order of responses if needed?",
    "Date and Time: 2020-11-05T14:05:21Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: Thank you for taking out the time to write this. <br>You are absolutely correct that dev tool CSS selectors and XPath are mostly not reliable.<br><br>In this video, I intentionally did not touch on that so that focus is on CSV/EXCEL and start_requests() method. <br><br>Just for fun, here are a few more XPaths for the same element: <br>//*[starts-with(@class,&quot;fs-body3&quot;)] &lt;- You suggested<br>//*[contains(@class,&quot;fs-body3&quot;)] &lt;- I use this a lot<br>//div[contains(text(),&quot;questions&quot;)] &lt;-div is important. Very useful in some scenarios<br>//div[contains(text(),&quot;questions&quot;) and contains(@class,&quot;fs-body3&quot;)] &lt;- combine both for robustness",
    "Date and Time: 2020-10-23T10:59:00Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @python360",
    "Reply: @@codeRECODE Ah yes, I do like the 4th one, combining the class name AND the text!<br>You have a new subscriber btw!",
    "Date and Time: 2020-10-23T11:10:38Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: @@python360 Thank you!",
    "Date and Time: 2020-10-23T11:15:32Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: You can Increase timeout in Settings. Check documentation.",
    "Date and Time: 2020-10-09T06:53:47Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2020-10-26T06:19:03Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: Pycharm + Kite plug-in = BEST!",
    "Date and Time: 2020-10-02T06:50:24Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: Be warned that Pycharm takes up resources. Quite a lot of people like VS Code, and I use that too. It&#39;s not a match for PyCharm<br>I know Visual Studio very well, but that is also is not a match for Pycharm when it comes to Python. <br><br>Another note: Visual Studio and Visual Studio Code are two completely different products.",
    "Date and Time: 2020-10-02T06:58:05Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: Interesting idea for another video.<br>To keep things simple, you can read your in the spider. If you know how to read database in any python file, you can apply same principles.  If not, wait for another video \ud83d\ude42",
    "Date and Time: 2020-09-30T03:02:51Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @ajayyadav-us8hd",
    "Reply: @@codeRECODE i have tried the way i am reading the data but i it was giving some error.<br>Thank you for you concern i&#39;ll wait for the video.",
    "Date and Time: 2020-09-30T14:05:03Z",
    " ",
    "Video Id: 6EyOq7zD628",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2020-10-26T06:19:46Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: Thanks Jake",
    "Date and Time: 2021-05-19T08:46:52Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: Thank you, Scrapy is really powerful!",
    "Date and Time: 2021-02-22T10:35:52Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: Thank you  :-)",
    "Date and Time: 2021-01-25T08:43:09Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: I am not sure how much I can post here on YouTube.  I am preparing a new section on my personal site. I Will post an update soon<br>!",
    "Date and Time: 2020-12-11T09:43:07Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: Check your selectors. Use shell to verify that the selectors are correct. CSV will have everything that you &quot;yield&quot;<br>If you want specific columns, specify that in <a href=\"http://settings.py/\">settings.py</a> as FEED_EXPORT_FIELDS",
    "Date and Time: 2020-08-18T05:28:50Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: Glad that it helped",
    "Date and Time: 2020-07-14T03:41:17Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: Coming up soon..<br>Trust me though, once you are comfortable with Scrapy, you will never look back at bs4 \ud83d\ude42",
    "Date and Time: 2020-06-21T13:50:22Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: Awesome, thank you!",
    "Date and Time: 2020-07-01T10:51:50Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: It should be available now.",
    "Date and Time: 2020-05-29T05:58:52Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: You can use pyinstaller for packaging the UI and scrapy. I don&#39;t have a ready example to share, may be I will give it a try",
    "Date and Time: 2020-05-28T15:59:51Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @huzaifabaloch2318",
    "Reply: Code / RECODE it would be great :)",
    "Date and Time: 2020-05-28T16:23:41Z",
    " ",
    "Video Id: YNeVP_zoYSg",
    "Replier Name: @codeRECODE",
    "Reply: Much appreciated!",
    "Date and Time: 2020-04-27T23:32:40Z",
    " ",
    "Video Id: YErdSlGiy48",
    "Replier Name: @codeRECODE",
    "Reply: Thank you! \ud83d\ude03",
    "Date and Time: 2022-10-27T04:30:39Z",
    " ",
    "Video Id: YErdSlGiy48",
    "Replier Name: @codeRECODE",
    "Reply: Better to use database. Even SQLite will do.",
    "Date and Time: 2022-09-01T01:54:09Z",
    " ",
    "Video Id: YErdSlGiy48",
    "Replier Name: @mayankmishra4637",
    "Reply: \u200b@@codeRECODE thanks for the suggestion. Will do that.",
    "Date and Time: 2022-09-02T07:49:15Z",
    " ",
    "Video Id: YErdSlGiy48",
    "Replier Name: @codeRECODE",
    "Reply: Yes, thank you for bringing it up. Here is the updated code:<br><a href=\"https://gist.github.com/eupendra/e84d54ae01c9b224ad1e1cccd91af77f\">https://gist.github.com/eupendra/e84d54ae01c9b224ad1e1cccd91af77f</a>",
    "Date and Time: 2022-08-31T10:43:46Z",
    " ",
    "Video Id: YErdSlGiy48",
    "Replier Name: @codeRECODE",
    "Reply: Glad it was helpful!",
    "Date and Time: 2022-01-21T04:04:20Z",
    " ",
    "Video Id: YErdSlGiy48",
    "Replier Name: @codeRECODE",
    "Reply: Great suggestion!",
    "Date and Time: 2022-01-21T04:07:09Z",
    " ",
    "Video Id: YErdSlGiy48",
    "Replier Name: @bchoor",
    "Reply: +1 on this request",
    "Date and Time: 2022-03-25T02:00:12Z",
    " ",
    "Video Id: YErdSlGiy48",
    "Replier Name: @codeRECODE",
    "Reply: Something like scrapyd?<br>Sure!",
    "Date and Time: 2022-01-14T15:27:03Z",
    " ",
    "Video Id: YErdSlGiy48",
    "Replier Name: @codeRECODE",
    "Reply: Most welcome \ud83d\ude0a",
    "Date and Time: 2022-01-15T06:37:52Z",
    " ",
    "Video Id: z5aOoKc4EKo",
    "Replier Name: @codeRECODE",
    "Reply: Keep watching :-)",
    "Date and Time: 2021-09-21T08:30:23Z",
    " ",
    "Video Id: z5aOoKc4EKo",
    "Replier Name: @codeRECODE",
    "Reply: Share your code: <a href=\"https://coderecode.com/submit-request/\">https://coderecode.com/submit-request/</a>",
    "Date and Time: 2021-10-07T07:09:06Z",
    " ",
    "Video Id: z5aOoKc4EKo",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-09-02T06:36:13Z",
    " ",
    "Video Id: cFuTTydm5bQ",
    "Replier Name: @codeRECODE",
    "Reply: I publish 3 or 4 videos every month. Hope you are subscribed with Notification :-)",
    "Date and Time: 2021-07-30T13:19:53Z",
    " ",
    "Video Id: cFuTTydm5bQ",
    "Replier Name: @codeRECODE",
    "Reply: Whatever gets the job done :-)",
    "Date and Time: 2021-06-12T02:45:46Z",
    " ",
    "Video Id: cFuTTydm5bQ",
    "Replier Name: @codeRECODE",
    "Reply: Selector Gadget is not always accurate. Always verify the selector generated by this tool. Also, watch my videos on XPATH and CSS selectors to understand selectors in depth. Cheers!",
    "Date and Time: 2021-04-15T02:10:42Z",
    " ",
    "Video Id: cFuTTydm5bQ",
    "Replier Name: @virajpatel8873",
    "Reply: @@codeRECODE thank you sir, will see it now :)",
    "Date and Time: 2021-04-15T02:36:59Z",
    " ",
    "Video Id: cFuTTydm5bQ",
    "Replier Name: @codeRECODE",
    "Reply: Its Down Arrow not page down.<br>Ctrl+Shift+Alt+Down Arrow to create multiple cursors vertically<br>Or Just press and hold ALT and click at all the places you want to create multiple cursors",
    "Date and Time: 2021-04-15T02:15:47Z",
    " ",
    "Video Id: cFuTTydm5bQ",
    "Replier Name: @codeRECODE",
    "Reply: Interesting question and observations! <br>We can solve this using XPath easily. There are two ways to do it. First is the &#39;correct&#39; way and second is a quick hack. It is important to understand both and use whatever you like:<br>1. descendant-or-self::* selects the current node and ALL of its descendants. So the XPath would be:<br>.//p[1]/descendant-or-self::*<br><br>We can add /text() to get the text inside these nodes. HOWEVER, we will have to use getall() and this will result in a list.<br><br>Now we would need to using string.join method of Python to get a string.<br>This is how the final line is going to look like<br>summary_list = blog.xpath(&#39;.//p[1]/descendant-or-self::*/text()&#39;).getall()<br>summary  =&#39;&#39;.join(summary_list)<br><br>2. Quick hack: use normalize-space of Xpath<br><br>summary = blog.xpath(&#39;normalize-space(.//p[1])&#39;).get()<br><br>Good luck and thank you for this question.",
    "Date and Time: 2020-07-11T05:22:47Z",
    " ",
    "Video Id: cFuTTydm5bQ",
    "Replier Name: @codeRECODE",
    "Reply: If you use CSS selectors, the solution is this:<br>summary_list = blog.css(&#39;p:nth-child(1) ::text&#39;).getall()<br>summary  =&#39;&#39;.join(summary_list)<br><br>OR as I would write it, merge both the lines in one:<br><br>summary = &#39;&#39;.join(blog.css(&#39;p:nth-child(1) ::text&#39;).getall())",
    "Date and Time: 2020-07-11T05:31:29Z",
    " ",
    "Video Id: cFuTTydm5bQ",
    "Replier Name: @ByteRiddler",
    "Reply: @@codeRECODE thank you for your quick reply, i have successfully implemented your xpath solution (i knew there had to be a better/easier way). I have also implemented a cleansing of the unicode from the retrieved data, though it is far from elegant, it works.<br>ucode = &quot;\\u00a0&quot;\r<br>            try:\r<br>                title = a.xpath(&quot;./header/h2/a/text()&quot;).get()\r<br>                clean_title = title.replace(ucode, &#39; &#39;).strip()\r<br>\r<br>                entry_list = a.xpath(&quot;./div/p[1]/descendant-or-self::*/text()&quot;).getall()\r<br>                clean_entry = &#39;&#39;.join(entry_list).replace(ucode, &#39; &#39;).strip()\r<br>            except Exception as e:\r<br>                print(&quot;Error processing text:&quot;, e)",
    "Date and Time: 2020-07-11T15:04:15Z",
    " ",
    "Video Id: cFuTTydm5bQ",
    "Replier Name: @taimoor722",
    "Reply: i am subscribed :)  please explain things like Mapcompose itemloader  i did a prroject with selenium can you please tell if it is possible to do with only using scrappy  link is below<br><br><a href=\"https://www.youtube.com/watch?v=UkyqlUZs_yA&amp;t=1s\">https://www.youtube.com/watch?v=UkyqlUZs_yA&amp;t=1s</a>",
    "Date and Time: 2020-04-01T08:41:11Z",
    " ",
    "Video Id: H_lVwUW_qaI",
    "Replier Name: @codeRECODE",
    "Reply: You are so welcome!",
    "Date and Time: 2022-02-09T12:27:45Z",
    " ",
    "Video Id: H_lVwUW_qaI",
    "Replier Name: @codeRECODE",
    "Reply: Keep watching",
    "Date and Time: 2021-02-24T10:03:25Z",
    " ",
    "Video Id: H_lVwUW_qaI",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear it!",
    "Date and Time: 2021-02-13T11:51:13Z",
    " ",
    "Video Id: H_lVwUW_qaI",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-01-29T06:06:56Z",
    " ",
    "Video Id: H_lVwUW_qaI",
    "Replier Name: @codeRECODE",
    "Reply: Thanks a lot :-)<br>100k, let&#39;s do this!",
    "Date and Time: 2021-01-29T04:13:54Z",
    " ",
    "Video Id: H_lVwUW_qaI",
    "Replier Name: @codeRECODE",
    "Reply: Thanks \ud83d\ude42<br>Looks like you need to look into crawl spiders. You can generate one using Scrapy genspider -t crawl spidername<br>I am going to add this to my next video list. Thanks for the suggestion",
    "Date and Time: 2021-01-28T15:58:53Z",
    " ",
    "Video Id: H_lVwUW_qaI",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear it!",
    "Date and Time: 2021-02-13T11:51:29Z",
    " ",
    "Video Id: H_lVwUW_qaI",
    "Replier Name: @codeRECODE",
    "Reply: Sure \ud83d\udc4d",
    "Date and Time: 2021-01-28T11:05:23Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: It&#39;s a custom method to remove all whitespaces. See the source code here- <a href=\"https://github.com/eupendra/scraper-helper/blob/master/src/scraper_helper/text.py\">https://github.com/eupendra/scraper-helper/blob/master/src/scraper_helper/text.py</a>",
    "Date and Time: 2022-06-27T05:15:59Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @umerimran3833",
    "Reply: @@codeRECODE thank you sir for the reply",
    "Date and Time: 2022-06-27T12:07:00Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: <a href=\"https://youtu.be/RgdaP54RvUM\">https://youtu.be/RgdaP54RvUM</a>",
    "Date and Time: 2022-03-26T13:02:06Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @adc9640",
    "Reply: And so the same issue occurs for me in <a href=\"https://www.youtube.com/watch?v=l0chQxDJJWU&amp;t=12m29s\">12:29</a> of the video with the xpath method. The code returns the &lt;h6&gt;...&lt;/h6&gt; element plus the rest of the html code.",
    "Date and Time: 2022-03-11T02:53:11Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: Hey, so I wrote an answer for your question on stack overflow!",
    "Date and Time: 2022-03-18T17:17:56Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: Thank you \ud83d\ude42",
    "Date and Time: 2022-01-04T02:30:17Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: Glad to hear that",
    "Date and Time: 2021-12-08T04:39:20Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: If the output is different with scrapy and selenium then most probably there is some dynamic content on the page. In this case, it is the quantity. Here is what I would suggest:<br>1. Rule out dynamic content. The easiest way is to copy this 1755 number and search it in View Source. <br>2. If it is dynamic, sometimes it will be simply a separate request to another URL. You can replicate the same.<br>3. Open the URL in scrapy shell and verify your selector there. DO NOT compare selenium output with what you get in scrapy. <br>Let me know how it goes",
    "Date and Time: 2021-10-09T10:42:05Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: If you like, you can send the details using this page - <a href=\"https://coderecode.com/submit-request/\">https://coderecode.com/submit-request/</a><br>Please note that even though I try my best, because of the sheer volume of requests I get, I may or may not be able to reply to you. <br>In either case, I may be able to help the community by covering this in a future video.",
    "Date and Time: 2021-10-09T10:44:40Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: Its Scraper_helper not scrapy_helper",
    "Date and Time: 2021-07-06T03:10:29Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: Use something like:<br>result =response.xpath(&#39;your_xpath&#39;).xpath(&#39;.//text()&#39;).getall() to get a list of strings.<br>and then use &#39;&#39;.join(result) to get one string.",
    "Date and Time: 2021-07-02T06:02:08Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @abukaium2106",
    "Reply: @@codeRECODE thanks a lot,sir.",
    "Date and Time: 2021-07-02T08:04:55Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: You&#39;re welcome!",
    "Date and Time: 2021-05-25T07:42:42Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: So nice of you",
    "Date and Time: 2021-04-19T06:48:22Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: sure I will add cookies handling to the video idea.<br>cookies are automatically handled by scrapy. If you need to get a specific key out of the cookie, you can use  response.headers.getlist(&#39;Set-Cookie&#39;)",
    "Date and Time: 2021-03-05T06:01:05Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: //h2[@class=xyz]/../ul",
    "Date and Time: 2021-03-04T15:52:58Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-03-04T12:15:21Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: Great! Keep watching :-)",
    "Date and Time: 2021-03-05T18:58:15Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: Thank you! Cheers!",
    "Date and Time: 2021-03-05T18:57:51Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: Great! Happy to hear that<br> :-)",
    "Date and Time: 2021-03-05T18:58:34Z",
    " ",
    "Video Id: l0chQxDJJWU",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it \ud83d\ude42",
    "Date and Time: 2021-03-03T15:29:07Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @codeRECODE",
    "Reply: You will have to study the network traffic. See what happens when you click the next button. Most probably it is a post request where the next page is being sent as a parameter. It really depends on the site.",
    "Date and Time: 2021-10-07T07:06:39Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @UpendraSinghai",
    "Reply: See what happens when you change the dropdown in the network tab. Most commonly, it is a GET request. It may also be a POST request. In either case, see the headers, body, and URL. You can mimic the same in your code.",
    "Date and Time: 2021-09-20T12:19:21Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @codeRECODE",
    "Reply: It had sound issue. There was no audio in the right channel. That&#39;s why I set it to private. I&#39;ve recorded another one. I will be editing and posting it very soon",
    "Date and Time: 2021-07-11T13:40:47Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @codeRECODE",
    "Reply: Meanwhile I set the visibility to unlisted. if you already have the URL you can watch it. but I would recommend that you wait for a day two for the new and updated video",
    "Date and Time: 2021-07-11T13:43:09Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @gcu1",
    "Reply: @@codeRECODE Ok, thanks!  I&#39;ll watch the new one, but thanks for making this one available, too.",
    "Date and Time: 2021-07-12T02:54:53Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @codeRECODE",
    "Reply: Get the basics clear and try out the jobs posted on Upwork as practice projects. Once you feel comfortable, start applying. Good luck!",
    "Date and Time: 2021-07-13T05:47:58Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @codeRECODE",
    "Reply: request-html is in  my todo list. :-)",
    "Date and Time: 2021-07-02T05:59:27Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @earhba",
    "Reply: @@codeRECODE I will check .",
    "Date and Time: 2021-07-02T06:04:22Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @codeRECODE",
    "Reply: @@earhba i meant its in my todo list",
    "Date and Time: 2021-07-02T06:27:00Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @codeRECODE",
    "Reply: This may be helpful - <a href=\"https://docs.python-requests.org/en/master/user/advanced/\">https://docs.python-requests.org/en/master/user/advanced/</a>",
    "Date and Time: 2021-06-30T09:28:18Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @ashirbad7890",
    "Reply: @@codeRECODE It was difficult to follow from ths link , so asked here for more clarity. a short video is appreciated .",
    "Date and Time: 2021-07-04T04:22:44Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @codeRECODE",
    "Reply: Great idea.",
    "Date and Time: 2021-06-15T15:06:55Z",
    " ",
    "Video Id: dusjuqfNIyY",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked it \ud83d\ude42",
    "Date and Time: 2021-06-15T05:41:52Z",
    " ",
    "Video Id: AHuER2ryGvY",
    "Replier Name: @codeRECODE",
    "Reply: Create an HTML file with this as a template. In python script, read the file, do a string .replace(\u201c{{name}}\u201d, first_name)<br><br>Hope you get the idea.",
    "Date and Time: 2022-09-26T15:59:29Z",
    " ",
    "Video Id: AHuER2ryGvY",
    "Replier Name: @sayedhasanemon6274",
    "Reply: @@codeRECODE  Can you please give some hints? Or please make a vedio with it. I searched whole internet server, there is no single hints at all. Please take it under your consideration.",
    "Date and Time: 2022-09-26T17:34:03Z",
    " ",
    "Video Id: AHuER2ryGvY",
    "Replier Name: @codeRECODE",
    "Reply: Glad that you liked&#39;em",
    "Date and Time: 2021-12-04T05:58:38Z",
    " ",
    "Video Id: AHuER2ryGvY",
    "Replier Name: @codeRECODE",
    "Reply: Great idea!",
    "Date and Time: 2021-11-18T03:22:00Z",
    " ",
    "Video Id: AHuER2ryGvY",
    "Replier Name: @codeRECODE",
    "Reply: The theme is  Monokai Contrast. I have few colors further customized in the settings",
    "Date and Time: 2021-11-18T03:19:01Z",
    " ",
    "Video Id: AHuER2ryGvY",
    "Replier Name: @codeRECODE",
    "Reply: Thanks \ud83d\ude42",
    "Date and Time: 2021-11-16T15:59:55Z",
    " ",
    "Video Id: AHuER2ryGvY",
    "Replier Name: @codeRECODE",
    "Reply: First thank you. Thank you \ud83d\ude42",
    "Date and Time: 2021-11-16T14:46:12Z",
    " ",
    "Video Id: 77J5ssOrnzE",
    "Replier Name: @codeRECODE",
    "Reply: Thank you :-)",
    "Date and Time: 2021-12-27T12:35:00Z",
    " ",
    "Video Id: 77J5ssOrnzE",
    "Replier Name: @codeRECODE",
    "Reply: Estoy usando el traductor de Google para chatear. Me alegro de que mi video te haya ayudado. Pronto subir\u00e9 m\u00e1s videos :-)",
    "Date and Time: 2021-12-27T12:37:42Z",
    " ",
    "Video Id: 77J5ssOrnzE",
    "Replier Name: @codeRECODE",
    "Reply: Ctrl Shift P and then select Format<br>or ALT SHIFT F<br>You would also need to have an extension that can format JSON. For example, Beautify",
    "Date and Time: 2021-07-02T05:57:47Z",
    " ",
    "Video Id: 77J5ssOrnzE",
    "Replier Name: @codeRECODE",
    "Reply: Glad you liked it!",
    "Date and Time: 2021-06-21T12:29:30Z",
    " ",
    "Video Id: 77J5ssOrnzE",
    "Replier Name: @codeRECODE",
    "Reply: Create one dictionary (usually called item), store all the attributes (keys) in the first callback (parse) method. From that method, whenver you yield a new request, send this item dictionary and add new attributes/keys. It doesnt matter how many pages or websites it takes to fill the dictionary. Just keep passing it from one method to the next. Once everything is available, then yield item.",
    "Date and Time: 2021-04-03T05:49:22Z",
    " ",
    "Video Id: 77J5ssOrnzE",
    "Replier Name: @codeRECODE",
    "Reply: Thank you! Cheers!",
    "Date and Time: 2020-08-18T05:25:56Z",
    " ",
    "Video Id: 77J5ssOrnzE",
    "Replier Name: @codeRECODE",
    "Reply: Looks like the site is dynamic, rendered using JavaScript. Have a look at <a href=\"https://www.youtube.com/watch?v=Pu3gmdWsLYc\">https://www.youtube.com/watch?v=Pu3gmdWsLYc</a>",
    "Date and Time: 2020-04-30T00:49:40Z",
    " ",
    "Video Id: 77J5ssOrnzE",
    "Replier Name: @codeRECODE",
    "Reply: wlcm :-)",
    "Date and Time: 2020-04-27T23:04:38Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @codeRECODE",
    "Reply: You&#39;re welcome!",
    "Date and Time: 2022-08-06T13:34:54Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @codeRECODE",
    "Reply: Glad it helped!",
    "Date and Time: 2022-03-26T13:00:22Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @codeRECODE",
    "Reply: Hard to say anything without looking at the site. If you wish, you can share the site. Don&#39;t paste the link here. Comments with links are deleted by YouTube. Send the link here:<br><a href=\"https://coderecode.com/submit-request/\">https://coderecode.com/submit-request/</a>",
    "Date and Time: 2021-11-26T09:54:44Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @johnme60",
    "Reply: @@codeRECODE thanks I sent it. Please check .<br>You can make video if you want or reply to me but<br>Please reply here once when you acknowledged it.",
    "Date and Time: 2021-11-26T10:43:23Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @johnme60",
    "Reply: @@codeRECODE Hello sir , I wanted to share this thing to you  . I progressed in the question I sent you .<br><br>So the thing is :<br><br>This website was ignoring the api call. But I found this thing today, to me it looks funny. But maybe I don&#39;t have enough knowledge and there&#39;s something else going on.<br><br>I tried random client Id , with same length , and everyone of them getting 200.<br>How is this possible.<br><br>first request I made Is &quot;GET&quot;. <br>the second  one is &quot;POST&quot; , not FormRequest. <br><br>I made payload of form data and sent it in body parameter  by setting the method &quot;POST&quot; in scrapy request.<br><br>Note: I tried on different vpn connection, it&#39;s still working.<br><br><br>Although I solved the problem somehow , but I am curious to know , how and why this is happening . <br>Is it really random id generated by website or , I am missing something.<br><br><br>I sent you this request  on your website by name &quot;John&quot;, please make a video on it. It blew my mind for 3 days.<br><br>Thanks !",
    "Date and Time: 2021-11-28T12:27:18Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @codeRECODE",
    "Reply: I will make a dedicated video sometime soon. Meanwhile, I will suggest understanding how form post work. That should help.",
    "Date and Time: 2021-12-04T06:47:52Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @codeRECODE",
    "Reply: Thanks Humayun",
    "Date and Time: 2021-10-10T03:28:47Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @codeRECODE",
    "Reply: Yeah, it is little advanced problem solving \ud83d\ude03<br>Glad the you found informative",
    "Date and Time: 2021-10-09T08:23:00Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @codeRECODE",
    "Reply: You&#39;re welcome!",
    "Date and Time: 2021-10-07T07:06:46Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @codeRECODE",
    "Reply: welcome :-)",
    "Date and Time: 2021-10-05T05:55:45Z",
    " ",
    "Video Id: Tk5fPldIow0",
    "Replier Name: @codeRECODE",
    "Reply: Welcome \ud83d\ude0a",
    "Date and Time: 2021-10-04T16:13:21Z",
    " "
]